{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Marketplace Product Usage Demonstration - Model Packages\n",
    "\n",
    "## Using Model Package ARN with Amazon SageMaker APIs\n",
    "\n",
    "This sample notebook demonstrates how to use Source Separation model package listed on Amazon SageMaker Marketplace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefixes\n",
    "common_prefix = \"source_separation\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the session\n",
    "\n",
    "The session remembers our connection parameters to Amazon SageMaker. We'll use it to perform all of our Amazon SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "Now we use the above Model Package to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model package arn arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad\n"
     ]
    }
   ],
   "source": [
    "from src.source_separation_arns import ModelPackageArnProvider\n",
    "\n",
    "modelpackage_arn = ModelPackageArnProvider.get_model_package_arn(sagemaker_session.boto_region_name)\n",
    "print(\"Using model package arn \" + modelpackage_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "#from sagemaker.predictor import csv_serializer\n",
    "\n",
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform Job\n",
    "\n",
    "Now let's use the model built to run a batch inference job on multiple audio files.\n",
    "\n",
    "Add your input audio files to \"data/transform\" folder.\n",
    "\n",
    "Create a \"batch-transform-output\" folder in the data directory before running the cells below (if not created already)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-428712150059/source_separation/batch-inference-input-data\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\u001b[31mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[31m[2019-10-31 08:34:17 +0000] [11] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[31m[2019-10-31 08:34:17 +0000] [11] [INFO] Listening at: unix:/tmp/gunicorn.sock (11)\u001b[0m\n",
      "\u001b[31m[2019-10-31 08:34:17 +0000] [11] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[31m[2019-10-31 08:34:17 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[31m[2019-10-31 08:34:17 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[31m[2019-10-31 08:34:17 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[31m[2019-10-31 08:34:17 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[31mTesting...\u001b[0m\n",
      "\u001b[31m2019-10-31 08:34:32.776086: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m169.254.255.130 - - [31/Oct/2019:08:34:33 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[31m169.254.255.130 - - [31/Oct/2019:08:34:33 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[31mInput path : /tmp/audio_file_1572510873.096988.mp3\u001b[0m\n",
      "\u001b[31mProducing source estimates for input mixture file /tmp/audio_file_1572510873.096988.mp3\u001b[0m\n",
      "\u001b[31mTesting...\u001b[0m\n",
      "\u001b[31m2019-10-31 08:34:34.450322: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31mNum of variables64\u001b[0m\n",
      "\u001b[31mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[33m2019-10-31T08:34:33.071:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[31mWARNING: Given output path /opt/ml/output/ does not exist. Trying to create it...\u001b[0m\n",
      "\u001b[31m['audio_file_1572510873.096988.mp3_vocals.wav', 'audio_file_1572510873.096988.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[32mWARNING: Given output path /opt/ml/output/ does not exist. Trying to create it...\u001b[0m\n",
      "\u001b[32m['audio_file_1572510873.096988.mp3_vocals.wav', 'audio_file_1572510873.096988.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[31m169.254.255.130 - - [31/Oct/2019:08:35:19 +0000] \"POST /invocations HTTP/1.1\" 200 19220663 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[31mInput path : /tmp/audio_file_1572510919.321833.mp3\u001b[0m\n",
      "\u001b[31mProducing source estimates for input mixture file /tmp/audio_file_1572510919.321833.mp3\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [31/Oct/2019:08:35:19 +0000] \"POST /invocations HTTP/1.1\" 200 19220663 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32mInput path : /tmp/audio_file_1572510919.321833.mp3\u001b[0m\n",
      "\u001b[32mProducing source estimates for input mixture file /tmp/audio_file_1572510919.321833.mp3\u001b[0m\n",
      "\u001b[31mTesting...\u001b[0m\n",
      "\u001b[32mTesting...\u001b[0m\n",
      "\u001b[31m2019-10-31 08:35:20.739552: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31mNum of variables64\u001b[0m\n",
      "\u001b[31mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[32m2019-10-31 08:35:20.739552: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[32mNum of variables64\u001b[0m\n",
      "\u001b[32mPre-trained model restored for song prediction\u001b[0m\n",
      "\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-428712150059/source_separation/batch-transform-output\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import uuid\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://'+bucket+'/'+common_prefix+'/batch-transform-output')\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix2.mp3.out\n",
      "mix3.mp3.out\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'data/batch-transform-output/output-{}.zip'.format(i))\n",
    "    #with open('batch_results') as f:\n",
    "    #    results = f.readlines()\n",
    "    #    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-1.zip\n",
      "output-2.zip\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data/batch-transform-output'):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile('data/batch-transform-output/'+file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data/batch-transform-output/'+file.split('.')[0]+'/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Inference Endpoint\n",
    "\n",
    "Now we demonstrate the creation of an endpoint for live inference on a single audio file.\n",
    "\n",
    "Add your input audio file to \"data/inference\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: source-separation-v11570291536-75ed8128-2019-10-31-08-31-04-659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(1, 'ml.m4.xlarge', endpoint_name='source-separation-inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some data and use it for a prediction\n",
    "\n",
    "For inference of a single file enter one file in the \"data/inference\" folder. Enter the file name in input_file variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERENCE_WORKDIR = \"data/inference/\"\n",
    "\n",
    "input_file = \"mix1.mp3\" #Edit input filename here\n",
    "\n",
    "INFERENCE_FILE = INFERENCE_WORKDIR + input_file\n",
    "\n",
    "with open(INFERENCE_FILE, 'rb') as file:\n",
    "    b = file.read()\n",
    "    \n",
    "source_separation_output = predictor.predict(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the zip file from bytes output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/output.zip', 'wb') as file:\n",
    "    file.write(source_separation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting output files from the zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/output.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing the output files received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audio_file_1572514394.0904057.mp3_accompaniment.wav', 'audio_file_1572514394.0904057.mp3_vocals.wav']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('data/output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
