{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (4/4), done.\n",
      "From https://github.com/basilwong/awstest1\n",
      "   66882a7..324af85  master     -> origin/master\n",
      "Updating 66882a7..324af85\n",
      "Fast-forward\n",
      " source-separation-input/drake-toosie_slide.mp3 | Bin \u001b[31m5933485\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " source-separation-input/input1.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m480906\u001b[m bytes\n",
      " source-separation-input/input2.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m480906\u001b[m bytes\n",
      " source-separation-input/input3.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m480906\u001b[m bytes\n",
      " source-separation-input/input4.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m480906\u001b[m bytes\n",
      " source-separation-input/input5.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m480906\u001b[m bytes\n",
      " source-separation-input/input6.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m480906\u001b[m bytes\n",
      " source-separation-input/input7.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m480906\u001b[m bytes\n",
      " source-separation-input/input8.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m480906\u001b[m bytes\n",
      " source-separation-input/input9.mp3             | Bin \u001b[31m0\u001b[m -> \u001b[32m115191\u001b[m bytes\n",
      " src/audio_util.py                              |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " 11 files changed, 1 insertion(+), 1 deletion(-)\n",
      " delete mode 100644 source-separation-input/drake-toosie_slide.mp3\n",
      " create mode 100644 source-separation-input/input1.mp3\n",
      " create mode 100644 source-separation-input/input2.mp3\n",
      " create mode 100644 source-separation-input/input3.mp3\n",
      " create mode 100644 source-separation-input/input4.mp3\n",
      " create mode 100644 source-separation-input/input5.mp3\n",
      " create mode 100644 source-separation-input/input6.mp3\n",
      " create mode 100644 source-separation-input/input7.mp3\n",
      " create mode 100644 source-separation-input/input8.mp3\n",
      " create mode 100644 source-separation-input/input9.mp3\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.23.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from sagemaker import ModelPackage\n",
    "\n",
    "\n",
    "# some_file.py\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('src')\n",
    "\n",
    "!pip install pydub\n",
    "\n",
    "import audio_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution role\n",
    "role = get_execution_role()\n",
    "# S3 prefixes\n",
    "common_prefix = \"source_separation\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "# Sagemaker Session\n",
    "sagemaker_session = sage.Session()\n",
    "# Arn for Source Separator Model Package\n",
    "modelpackage_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "\n",
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Batch Job\n",
    "\n",
    "Note that if the initial audio file is longer than around 30 seconds, it is too large for the model. The split_mp3() method in  src.audio_util works around this by splitting an mp3 file into 30 second segments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-075178354542/source_separation/batch-inference-input-data\n"
     ]
    }
   ],
   "source": [
    "batch_input_folder = \"source-separation-input\"\n",
    "\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(batch_input_folder, key_prefix=batch_inference_input_prefix)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2020-04-12 10:41:46 +0000] [12] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2020-04-12 10:41:46 +0000] [12] [INFO] Listening at: unix:/tmp/gunicorn.sock (12)\u001b[0m\n",
      "\u001b[34m[2020-04-12 10:41:46 +0000] [12] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-04-12 10:41:46 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2020-04-12 10:41:47 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2020-04-12 10:41:47 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m[2020-04-12 10:41:47 +0000] [19] [INFO] Booting worker with pid: 19\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-12 10:42:08.875699: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:42:09 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:42:09 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688129.2001228.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688129.2001228.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m2020-04-12 10:42:08.875699: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:42:09 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:42:09 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688129.2001228.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688129.2001228.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[32m2020-04-12T10:42:09.170:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:42:55 +0000] \"POST /invocations HTTP/1.1\" 200 19391978 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688175.3730624.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688175.3730624.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:42:55 +0000] \"POST /invocations HTTP/1.1\" 200 19391978 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688175.3730624.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688175.3730624.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-12 10:42:56.841409: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35m2020-04-12 10:42:56.841409: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688221.484059.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688221.484059.mp3\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688221.484059.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688221.484059.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-12 10:43:42.891095: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35m2020-04-12 10:43:42.891095: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688267.341563.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688267.341563.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688267.341563.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688267.341563.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-12 10:44:28.782040: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m2020-04-12 10:44:28.782040: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:45:13 +0000] \"POST /invocations HTTP/1.1\" 200 19435231 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688313.4434075.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688313.4434075.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:45:13 +0000] \"POST /invocations HTTP/1.1\" 200 19435231 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688313.4434075.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688313.4434075.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:45:59 +0000] \"POST /invocations HTTP/1.1\" 200 19477349 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688359.6707158.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688359.6707158.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:45:59 +0000] \"POST /invocations HTTP/1.1\" 200 19477349 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688359.6707158.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688359.6707158.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:46:45 +0000] \"POST /invocations HTTP/1.1\" 200 19460915 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688405.760855.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688405.760855.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:46:45 +0000] \"POST /invocations HTTP/1.1\" 200 19460915 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688405.760855.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688405.760855.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:47:31 +0000] \"POST /invocations HTTP/1.1\" 200 19459098 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688451.638458.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688451.638458.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:47:31 +0000] \"POST /invocations HTTP/1.1\" 200 19459098 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688451.638458.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688451.638458.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:48:17 +0000] \"POST /invocations HTTP/1.1\" 200 19035680 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586688497.7542431.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586688497.7542431.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:48:17 +0000] \"POST /invocations HTTP/1.1\" 200 19035680 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586688497.7542431.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586688497.7542431.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:48:30 +0000] \"POST /invocations HTTP/1.1\" 200 4379043 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:48:30 +0000] \"POST /invocations HTTP/1.1\" 200 4379043 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:10:48:30 +0000] \"POST /invocations HTTP/1.1\" 200 4379043 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:10:48:30 +0000] \"POST /invocations HTTP/1.1\" 200 4379043 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-075178354542/source_separation/batch-transform-output\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import uuid\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://'+bucket+'/'+common_prefix+'/batch-transform-output')\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Batch Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1.mp3.out\n",
      "input2.mp3.out\n",
      "input3.mp3.out\n",
      "input4.mp3.out\n",
      "input5.mp3.out\n",
      "input6.mp3.out\n",
      "input7.mp3.out\n",
      "input8.mp3.out\n",
      "input9.mp3.out\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "audio_util.clear_folder('source-separation-output/batch-transform-output')\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'source-separation-output/batch-transform-output/output-{}.zip'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-3.zip\n",
      "output-6.zip\n",
      "output-8.zip\n",
      "output-9.zip\n",
      "output-1.zip\n",
      "output-4.zip\n",
      "output-7.zip\n",
      "output-2.zip\n",
      "output-5.zip\n"
     ]
    }
   ],
   "source": [
    "# Extracting files from zip files. \n",
    "audio_util.clear_folder('source-separation-output/extracted')\n",
    "for file in os.listdir('source-separation-output/batch-transform-output'):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile('source-separation-output/batch-transform-output/'+file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('source-separation-output/extracted/'+file.split('.')[0]+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0audio_file_1586688313.4434075.mp3_accompaniment.wav\n",
      "0audio_file_1586688313.4434075.mp3_vocals.wav\n",
      "1audio_file_1586688359.6707158.mp3_vocals.wav\n",
      "1audio_file_1586688359.6707158.mp3_accompaniment.wav\n",
      "2audio_file_1586688451.638458.mp3_accompaniment.wav\n",
      "2audio_file_1586688451.638458.mp3_vocals.wav\n",
      "3audio_file_1586688129.2001228.mp3_vocals.wav\n",
      "3audio_file_1586688129.2001228.mp3_accompaniment.wav\n",
      "4audio_file_1586688267.341563.mp3_vocals.wav\n",
      "4audio_file_1586688267.341563.mp3_accompaniment.wav\n",
      "5audio_file_1586688221.484059.mp3_accompaniment.wav\n",
      "5audio_file_1586688221.484059.mp3_vocals.wav\n",
      "6audio_file_1586688175.3730624.mp3_accompaniment.wav\n",
      "6audio_file_1586688175.3730624.mp3_vocals.wav\n",
      "7audio_file_1586688497.7542431.mp3_vocals.wav\n",
      "7audio_file_1586688497.7542431.mp3_accompaniment.wav\n",
      "8audio_file_1586688405.760855.mp3_accompaniment.wav\n",
      "8audio_file_1586688405.760855.mp3_vocals.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Separating the vocal files and the background sound files.\n",
    "audio_util.clear_folder('source-separation-output/vocals')\n",
    "audio_util.clear_folder('source-separation-output/background')\n",
    "for i, folder in enumerate(os.listdir('source-separation-output/extracted/')):\n",
    "    for file in os.listdir('source-separation-output/extracted/' + folder + '/output'):\n",
    "        print(str(i) + file)\n",
    "        if \"vocals\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/vocals/' + str(i) + file)\n",
    "        elif \"accompaniment\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/background/' + str(i) + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Vocal Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribe input uploaded to s3://sagemaker-us-east-2-075178354542/transcribe-input\n"
     ]
    }
   ],
   "source": [
    "# Upload the Vocal files onto s3\n",
    "local_vocals_folder = \"source-separation-output/vocals/\"\n",
    "transcribe_input_prefix = \"transcribe-input\"\n",
    "\n",
    "transcribe_input = sagemaker_session.upload_data(local_vocals_folder, key_prefix=transcribe_input_prefix)\n",
    "print(\"Transcribe input uploaded to \" + transcribe_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TranscriptionJob': {'TranscriptionJobName': 'tester1', 'TranscriptionJobStatus': 'COMPLETED', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 44100, 'MediaFormat': 'wav', 'Media': {'MediaFileUri': 'https://sagemaker-us-east-2-075178354542.s3.us-east-2.amazonaws.com/transcribe-input/0audio_file_1586688313.4434075.mp3_vocals.wav'}, 'Transcript': {'TranscriptFileUri': 'https://s3.us-east-2.amazonaws.com/aws-transcribe-us-east-2-prod/075178354542/tester1/167826fc-0a6b-40a5-9d80-d555bf8e2cc8/asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDsaCXVzLWVhc3QtMiJGMEQCIHtUTq6DM8hxm%2BWULGwq01NjfRZBXZPXPkHU1Nh6jS98AiA8paqPgQZknQspD59ZOn4TIMojWkhaP%2Bqdzc6esbdPJSq0AwhUEAEaDDI0NjM2MTMyMjc1MiIM%2B8Pbi5mxWpiplhFqKpEDgtAijENS3UMjKYNsq25jkr9oyae7aI19UgGWtVISQF8SB08n%2Boi8mkGPVjeMI87GxZqRnoVqrwZE12bMKm4M%2B0tuczNvD2daSmPgJU6BBcpNdGLZ74Cl59%2BOrk4boS0Z9oydaOtTo0oF%2Ff72jm7wpCP%2FYw82o%2BL7fMncdkDfSJ%2Bzp%2FReyeiaF48MAaXxB9Z8zyo0UIdecB686Cs6ARIo9c6AoHwo1BDUZm9oEACQ2%2BMRYXp%2BTdqSSEz6m%2F9VHhC6cjT8O36Ro1jFe%2FKT4Adx9yK70xeeyZY6xZ6TUoqvrhP9%2B1cM3dYvgY4WKi3L3CzoABnG7BC9X2vWTxX5oKXSGoymnu4BAxk1aaJTS53O7Tx3Wk1ki%2BoTM9vv%2BoFeq1QQZZdyD%2Bw9%2Biodw9B60MKCZ2aXKwhpRorFvCz6%2FBOb9iV8CcU4SLj%2FabbQRECw9XhbbTnlFKPsuCvwLvpamXIvVFUv%2BiJVXXoNGSrw2jXaTnpUtcJicKaGtB6eQ3QX7XM1LS1WbrMQY67x5775O1JfQbEw6KPP9AU67AE0Znw18OoT3wPr4Dh3Z%2B%2BnKTT52yj%2BuCgDppyL%2BDFApx0zVr%2BerB9GLwCAREQD48B5K5V74S6yxAZO7D3UsvHdsMI74YSwjKFWw0oVkao%2B%2BZh6ygUL9KBThGtJ2MMbpzQjDISjbs8sbK%2BB2c7r7z0VPZGxyFhfH05U5Cy0hUwXU38kuCW2DToL%2FM3ajGgKLftYb%2FWIdPsFXx569tQhE5vb3aumPyhpVQ5OlgfOS91sTTq1L9E2d%2BCe1Sd%2FToKfc6DTRr9CzKYhmzPMJcl1YYrVz%2FMcihV%2BiEebPt2x4HJK1gO5o06rYLAtDZsvjw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200413T032721Z&X-Amz-SignedHeaders=host&X-Amz-Expires=900&X-Amz-Credential=ASIATSXCHOUACDHUFFQL%2F20200413%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Signature=335caeed7a84b99ddd352f863a6c12dffcf77a3bcfd0b78e045510f713fab8bb'}, 'StartTime': datetime.datetime(2020, 4, 13, 3, 25, 11, 281000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 4, 13, 3, 25, 11, 262000, tzinfo=tzlocal()), 'CompletionTime': datetime.datetime(2020, 4, 13, 3, 27, 21, 111000, tzinfo=tzlocal()), 'Settings': {'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '8dbfebf3-3fbf-4eb9-bd73-4c16f175ac29', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Mon, 13 Apr 2020 03:27:21 GMT', 'x-amzn-requestid': '8dbfebf3-3fbf-4eb9-bd73-4c16f175ac29', 'content-length': '2070', 'connection': 'keep-alive'}, 'RetryAttempts': 1}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "file = \"0audio_file_1586688313.4434075.mp3_vocals.wav\"\n",
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "uri_prefix = \"https://sagemaker-us-east-2-075178354542.s3.us-east-2.amazonaws.com/transcribe-input/\"\n",
    "job_uri = uri_prefix + file\n",
    "job_name = \"tester1\"\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    Media={'MediaFileUri': job_uri},\n",
    "    MediaFormat='wav',\n",
    "    LanguageCode='en-US',\n",
    ")\n",
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jobName': 'tester1', 'accountId': '075178354542', 'results': {'transcripts': [{'transcript': \"that foot right foot. Basically, I'm saying Either way we about so I can let this one slide to see Slide. Then I hated double time and I hit a Schmidt because we spent a block a couple times. If it's not the right time, I will always be another time. I'm not even tripping with him in a sometime. You can't describe the pressure of you putting know myself, really. I just can't afford a little nobody get a move on. Shaky with.\"}], 'items': [{'start_time': '0.52', 'end_time': '0.88', 'alternatives': [{'confidence': '0.9907', 'content': 'that'}], 'type': 'pronunciation'}, {'start_time': '0.89', 'end_time': '1.31', 'alternatives': [{'confidence': '0.9762', 'content': 'foot'}], 'type': 'pronunciation'}, {'start_time': '1.88', 'end_time': '2.4', 'alternatives': [{'confidence': '1.0', 'content': 'right'}], 'type': 'pronunciation'}, {'start_time': '2.41', 'end_time': '2.78', 'alternatives': [{'confidence': '0.9922', 'content': 'foot'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': '.'}], 'type': 'punctuation'}, {'start_time': '3.41', 'end_time': '4.08', 'alternatives': [{'confidence': '0.9993', 'content': 'Basically'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': ','}], 'type': 'punctuation'}, {'start_time': '4.08', 'end_time': '4.16', 'alternatives': [{'confidence': '0.9788', 'content': \"I'm\"}], 'type': 'pronunciation'}, {'start_time': '4.16', 'end_time': '4.66', 'alternatives': [{'confidence': '0.9985', 'content': 'saying'}], 'type': 'pronunciation'}, {'start_time': '4.66', 'end_time': '4.92', 'alternatives': [{'confidence': '0.9976', 'content': 'Either'}], 'type': 'pronunciation'}, {'start_time': '4.92', 'end_time': '5.17', 'alternatives': [{'confidence': '1.0', 'content': 'way'}], 'type': 'pronunciation'}, {'start_time': '5.17', 'end_time': '5.31', 'alternatives': [{'confidence': '0.8753', 'content': 'we'}], 'type': 'pronunciation'}, {'start_time': '5.31', 'end_time': '5.6', 'alternatives': [{'confidence': '0.4227', 'content': 'about'}], 'type': 'pronunciation'}, {'start_time': '5.6', 'end_time': '5.8', 'alternatives': [{'confidence': '0.804', 'content': 'so'}], 'type': 'pronunciation'}, {'start_time': '5.8', 'end_time': '6.33', 'alternatives': [{'confidence': '0.9775', 'content': 'I'}], 'type': 'pronunciation'}, {'start_time': '6.34', 'end_time': '6.68', 'alternatives': [{'confidence': '0.4705', 'content': 'can'}], 'type': 'pronunciation'}, {'start_time': '6.68', 'end_time': '6.84', 'alternatives': [{'confidence': '0.9963', 'content': 'let'}], 'type': 'pronunciation'}, {'start_time': '6.84', 'end_time': '7.02', 'alternatives': [{'confidence': '1.0', 'content': 'this'}], 'type': 'pronunciation'}, {'start_time': '7.02', 'end_time': '7.13', 'alternatives': [{'confidence': '0.9827', 'content': 'one'}], 'type': 'pronunciation'}, {'start_time': '7.13', 'end_time': '7.59', 'alternatives': [{'confidence': '0.9665', 'content': 'slide'}], 'type': 'pronunciation'}, {'start_time': '10.83', 'end_time': '11.03', 'alternatives': [{'confidence': '0.955', 'content': 'to'}], 'type': 'pronunciation'}, {'start_time': '11.03', 'end_time': '11.17', 'alternatives': [{'confidence': '0.938', 'content': 'see'}], 'type': 'pronunciation'}, {'start_time': '11.17', 'end_time': '11.64', 'alternatives': [{'confidence': '0.9974', 'content': 'Slide'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': '.'}], 'type': 'punctuation'}, {'start_time': '11.64', 'end_time': '11.82', 'alternatives': [{'confidence': '0.9997', 'content': 'Then'}], 'type': 'pronunciation'}, {'start_time': '11.82', 'end_time': '12.01', 'alternatives': [{'confidence': '1.0', 'content': 'I'}], 'type': 'pronunciation'}, {'start_time': '12.02', 'end_time': '12.34', 'alternatives': [{'confidence': '0.3715', 'content': 'hated'}], 'type': 'pronunciation'}, {'start_time': '12.34', 'end_time': '12.63', 'alternatives': [{'confidence': '1.0', 'content': 'double'}], 'type': 'pronunciation'}, {'start_time': '12.63', 'end_time': '13.12', 'alternatives': [{'confidence': '0.9874', 'content': 'time'}], 'type': 'pronunciation'}, {'start_time': '13.12', 'end_time': '13.34', 'alternatives': [{'confidence': '1.0', 'content': 'and'}], 'type': 'pronunciation'}, {'start_time': '13.34', 'end_time': '13.41', 'alternatives': [{'confidence': '0.9658', 'content': 'I'}], 'type': 'pronunciation'}, {'start_time': '13.42', 'end_time': '13.63', 'alternatives': [{'confidence': '0.9842', 'content': 'hit'}], 'type': 'pronunciation'}, {'start_time': '13.63', 'end_time': '13.69', 'alternatives': [{'confidence': '0.9617', 'content': 'a'}], 'type': 'pronunciation'}, {'start_time': '13.69', 'end_time': '14.1', 'alternatives': [{'confidence': '0.8806', 'content': 'Schmidt'}], 'type': 'pronunciation'}, {'start_time': '14.11', 'end_time': '14.36', 'alternatives': [{'confidence': '0.9167', 'content': 'because'}], 'type': 'pronunciation'}, {'start_time': '14.36', 'end_time': '14.46', 'alternatives': [{'confidence': '0.9894', 'content': 'we'}], 'type': 'pronunciation'}, {'start_time': '14.46', 'end_time': '14.79', 'alternatives': [{'confidence': '0.3495', 'content': 'spent'}], 'type': 'pronunciation'}, {'start_time': '14.79', 'end_time': '14.85', 'alternatives': [{'confidence': '0.2818', 'content': 'a'}], 'type': 'pronunciation'}, {'start_time': '14.85', 'end_time': '15.15', 'alternatives': [{'confidence': '0.9764', 'content': 'block'}], 'type': 'pronunciation'}, {'start_time': '15.15', 'end_time': '15.26', 'alternatives': [{'confidence': '0.9863', 'content': 'a'}], 'type': 'pronunciation'}, {'start_time': '15.27', 'end_time': '15.57', 'alternatives': [{'confidence': '1.0', 'content': 'couple'}], 'type': 'pronunciation'}, {'start_time': '15.58', 'end_time': '16.07', 'alternatives': [{'confidence': '1.0', 'content': 'times'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': '.'}], 'type': 'punctuation'}, {'start_time': '16.07', 'end_time': '16.22', 'alternatives': [{'confidence': '0.9985', 'content': 'If'}], 'type': 'pronunciation'}, {'start_time': '16.22', 'end_time': '16.37', 'alternatives': [{'confidence': '0.9949', 'content': \"it's\"}], 'type': 'pronunciation'}, {'start_time': '16.37', 'end_time': '16.59', 'alternatives': [{'confidence': '1.0', 'content': 'not'}], 'type': 'pronunciation'}, {'start_time': '16.59', 'end_time': '16.69', 'alternatives': [{'confidence': '1.0', 'content': 'the'}], 'type': 'pronunciation'}, {'start_time': '16.69', 'end_time': '17.1', 'alternatives': [{'confidence': '1.0', 'content': 'right'}], 'type': 'pronunciation'}, {'start_time': '17.1', 'end_time': '17.38', 'alternatives': [{'confidence': '1.0', 'content': 'time'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': ','}], 'type': 'punctuation'}, {'start_time': '17.38', 'end_time': '17.42', 'alternatives': [{'confidence': '0.6189', 'content': 'I'}], 'type': 'pronunciation'}, {'start_time': '17.42', 'end_time': '17.55', 'alternatives': [{'confidence': '0.783', 'content': 'will'}], 'type': 'pronunciation'}, {'start_time': '17.55', 'end_time': '17.84', 'alternatives': [{'confidence': '1.0', 'content': 'always'}], 'type': 'pronunciation'}, {'start_time': '17.85', 'end_time': '18.08', 'alternatives': [{'confidence': '1.0', 'content': 'be'}], 'type': 'pronunciation'}, {'start_time': '18.08', 'end_time': '18.49', 'alternatives': [{'confidence': '1.0', 'content': 'another'}], 'type': 'pronunciation'}, {'start_time': '18.49', 'end_time': '19.04', 'alternatives': [{'confidence': '1.0', 'content': 'time'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': '.'}], 'type': 'punctuation'}, {'start_time': '19.04', 'end_time': '19.16', 'alternatives': [{'confidence': '0.7798', 'content': \"I'm\"}], 'type': 'pronunciation'}, {'start_time': '19.16', 'end_time': '19.39', 'alternatives': [{'confidence': '1.0', 'content': 'not'}], 'type': 'pronunciation'}, {'start_time': '19.39', 'end_time': '19.63', 'alternatives': [{'confidence': '1.0', 'content': 'even'}], 'type': 'pronunciation'}, {'start_time': '19.64', 'end_time': '20.09', 'alternatives': [{'confidence': '0.9994', 'content': 'tripping'}], 'type': 'pronunciation'}, {'start_time': '20.09', 'end_time': '20.46', 'alternatives': [{'confidence': '1.0', 'content': 'with'}], 'type': 'pronunciation'}, {'start_time': '20.47', 'end_time': '20.84', 'alternatives': [{'confidence': '0.9334', 'content': 'him'}], 'type': 'pronunciation'}, {'start_time': '20.84', 'end_time': '20.97', 'alternatives': [{'confidence': '0.9994', 'content': 'in'}], 'type': 'pronunciation'}, {'start_time': '20.97', 'end_time': '21.03', 'alternatives': [{'confidence': '0.6689', 'content': 'a'}], 'type': 'pronunciation'}, {'start_time': '21.03', 'end_time': '22.13', 'alternatives': [{'confidence': '0.3312', 'content': 'sometime'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': '.'}], 'type': 'punctuation'}, {'start_time': '22.14', 'end_time': '22.43', 'alternatives': [{'confidence': '0.9871', 'content': 'You'}], 'type': 'pronunciation'}, {'start_time': '22.44', 'end_time': '22.83', 'alternatives': [{'confidence': '0.9719', 'content': \"can't\"}], 'type': 'pronunciation'}, {'start_time': '22.83', 'end_time': '23.22', 'alternatives': [{'confidence': '1.0', 'content': 'describe'}], 'type': 'pronunciation'}, {'start_time': '23.22', 'end_time': '23.3', 'alternatives': [{'confidence': '1.0', 'content': 'the'}], 'type': 'pronunciation'}, {'start_time': '23.3', 'end_time': '23.83', 'alternatives': [{'confidence': '0.9988', 'content': 'pressure'}], 'type': 'pronunciation'}, {'start_time': '23.88', 'end_time': '23.97', 'alternatives': [{'confidence': '0.7232', 'content': 'of'}], 'type': 'pronunciation'}, {'start_time': '23.97', 'end_time': '24.11', 'alternatives': [{'confidence': '0.8262', 'content': 'you'}], 'type': 'pronunciation'}, {'start_time': '24.11', 'end_time': '24.44', 'alternatives': [{'confidence': '0.9958', 'content': 'putting'}], 'type': 'pronunciation'}, {'start_time': '24.44', 'end_time': '24.61', 'alternatives': [{'confidence': '0.5815', 'content': 'know'}], 'type': 'pronunciation'}, {'start_time': '24.61', 'end_time': '25.12', 'alternatives': [{'confidence': '0.911', 'content': 'myself'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': ','}], 'type': 'punctuation'}, {'start_time': '25.58', 'end_time': '26.05', 'alternatives': [{'confidence': '0.9655', 'content': 'really'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': '.'}], 'type': 'punctuation'}, {'start_time': '26.05', 'end_time': '26.11', 'alternatives': [{'confidence': '1.0', 'content': 'I'}], 'type': 'pronunciation'}, {'start_time': '26.11', 'end_time': '26.31', 'alternatives': [{'confidence': '1.0', 'content': 'just'}], 'type': 'pronunciation'}, {'start_time': '26.31', 'end_time': '26.53', 'alternatives': [{'confidence': '0.9914', 'content': \"can't\"}], 'type': 'pronunciation'}, {'start_time': '26.53', 'end_time': '26.94', 'alternatives': [{'confidence': '1.0', 'content': 'afford'}], 'type': 'pronunciation'}, {'start_time': '26.94', 'end_time': '27.01', 'alternatives': [{'confidence': '0.9795', 'content': 'a'}], 'type': 'pronunciation'}, {'start_time': '27.01', 'end_time': '27.17', 'alternatives': [{'confidence': '0.9937', 'content': 'little'}], 'type': 'pronunciation'}, {'start_time': '27.17', 'end_time': '27.95', 'alternatives': [{'confidence': '0.9257', 'content': 'nobody'}], 'type': 'pronunciation'}, {'start_time': '28.52', 'end_time': '28.77', 'alternatives': [{'confidence': '0.3006', 'content': 'get'}], 'type': 'pronunciation'}, {'start_time': '28.77', 'end_time': '28.84', 'alternatives': [{'confidence': '0.3937', 'content': 'a'}], 'type': 'pronunciation'}, {'start_time': '28.84', 'end_time': '29.1', 'alternatives': [{'confidence': '0.1894', 'content': 'move'}], 'type': 'pronunciation'}, {'start_time': '29.1', 'end_time': '29.17', 'alternatives': [{'confidence': '0.1762', 'content': 'on'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': '.'}], 'type': 'punctuation'}, {'start_time': '29.17', 'end_time': '29.64', 'alternatives': [{'confidence': '0.9588', 'content': 'Shaky'}], 'type': 'pronunciation'}, {'start_time': '29.64', 'end_time': '29.98', 'alternatives': [{'confidence': '0.9998', 'content': 'with'}], 'type': 'pronunciation'}, {'alternatives': [{'confidence': '0.0', 'content': '.'}], 'type': 'punctuation'}]}, 'status': 'COMPLETED'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '381b2593-63f9-440e-8360-7b0c32a2c9a7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 13 Apr 2020 03:27:35 GMT',\n",
       "   'x-amzn-requestid': '381b2593-63f9-440e-8360-7b0c32a2c9a7',\n",
       "   'content-length': '0',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get(url=status['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "print(r.json())\n",
    "transcribe.delete_transcription_job(TranscriptionJobName=\"tester1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local_vocals_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2d8338bc6691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfinshed_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_vocals_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transcribing: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'local_vocals_folder' is not defined"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "output_bucket_name = \"transcribe-output\"\n",
    "uri_prefix = \"https://sagemaker-us-east-2-075178354542.s3.us-east-2.amazonaws.com/transcribe-input/\"\n",
    "finshed_jobs = dict()\n",
    "\n",
    "for file in os.listdir(local_vocals_folder):\n",
    "\n",
    "    print(\"Transcribing: \" + file)\n",
    "    print(\"Job: \" + str(i))\n",
    "    job_uri = uri_prefix + file\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=file,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='wav',\n",
    "        LanguageCode='en-US',\n",
    "    )\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "    \n",
    "    finished_jobs[file] = status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestException",
     "evalue": "An error occurred (BadRequestException) when calling the DeleteTranscriptionJob operation: The requested job couldn't be found. Check the job name and try your request again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-274f2982ca65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranscribe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_transcription_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTranscriptionJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'testjob2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequestException\u001b[0m: An error occurred (BadRequestException) when calling the DeleteTranscriptionJob operation: The requested job couldn't be found. Check the job name and try your request again."
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "audio_util.clear_folder('source-separation-output/batch-transform-output')\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'source-separation-output/batch-transform-output/output-{}.zip'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    \"\"\"Load in JSON file and return as dict\"\"\"\n",
    "\n",
    "    json_filepath = Path(file)\n",
    "    assert json_filepath.is_file(), \"JSON file does not exist\"\n",
    "\n",
    "    data = json.load(open(json_filepath.absolute(), \"r\", encoding=\"utf-8\"))\n",
    "    assert \"jobName\" in data\n",
    "    assert \"results\" in data\n",
    "    assert \"status\" in data\n",
    "\n",
    "    assert data[\"status\"] == \"COMPLETED\", \"JSON file not shown as completed.\"\n",
    "\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
