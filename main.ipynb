{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sagemaker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4207e075fb7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msagemaker\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_execution_role\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelPackage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sagemaker'"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os\n",
    "import json \n",
    "import uuid\n",
    "import requests\n",
    "\n",
    "# Installing src dependency.\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('src')\n",
    "\n",
    "!pip install pydub\n",
    "!pip install crepe\n",
    "\n",
    "import audio_util\n",
    "import processing_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://aws.amazon.com/marketplace/pp/prodview-23n4vi2zw67we to get the arn for the model package. \n",
    "\n",
    "***YOU NEED TO REPLACE THE STRING FOR THE ```modelpackage_arn``` VARIABLE WITH YOUR OWN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution role\n",
    "role = get_execution_role()\n",
    "# S3 prefixes\n",
    "common_prefix = \"source_separation\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "# Sagemaker Session\n",
    "sagemaker_session = sage.Session()\n",
    "# Arn for Source Separator Model Package\n",
    "modelpackage_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Corresponding IAM Role, add the following policies:\n",
    "\n",
    "* AmazonTranscribeFullAccess\n",
    "* AWSMarketplaceManageSubscriptions\n",
    "* AmazonPollyFullAccess\n",
    "* AmazonSageMakerFullAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Song for Input\n",
    "\n",
    "Note that if the initial audio file is longer than around 30 seconds, it is too large for the model. The split_mp3() method in  src.audio_util works around this by splitting an mp3 file into 30 second segments. \n",
    "\n",
    "This method requires ffmpeg as a dependency sice it uses pydub. Instead of installing it on the notebook, the code below was executed locally with ffmpeg installed. (```apt-get install ffmpeg``` for an Ubunutu machine, as I had trouble figuring out how to install it via yum). If anyone can figure it out please email me.\n",
    "\n",
    "But no worries the output of the split_mp3() method has already been added to this repository so no need to go execute it for demo purposes. \n",
    "\n",
    "Below here just choose what song you want to do the demo with by replacing the current song specified by the input_song variable with one of the songs below:\n",
    "\n",
    "* ```imagine-john_lennon```\n",
    "* ```toosie_slide-drake```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-075178354542/source_separation/batch-inference-input-data\n"
     ]
    }
   ],
   "source": [
    "input_song = \"imagine-john_lennon\"\n",
    "batch_input_folder = \"source-separation-input/\" + input_song + \"/\"\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(batch_input_folder, key_prefix=batch_inference_input_prefix)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Batch Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [11] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [11] [INFO] Listening at: unix:/tmp/gunicorn.sock (11)\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [11] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-15 00:40:07.431729: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:40:07 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:40:07 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911207.7691767.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911207.7691767.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[32m2020-04-15T00:40:07.738:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34mWARNING: Given output path /opt/ml/output/ does not exist. Trying to create it...\u001b[0m\n",
      "\u001b[34m['audio_file_1586911207.7691767.mp3_vocals.wav', 'audio_file_1586911207.7691767.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[35mWARNING: Given output path /opt/ml/output/ does not exist. Trying to create it...\u001b[0m\n",
      "\u001b[35m['audio_file_1586911207.7691767.mp3_vocals.wav', 'audio_file_1586911207.7691767.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:40:54 +0000] \"POST /invocations HTTP/1.1\" 200 18898524 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911254.9186606.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911254.9186606.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:40:54 +0000] \"POST /invocations HTTP/1.1\" 200 18898524 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911254.9186606.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911254.9186606.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-15 00:40:56.383541: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35m2020-04-15 00:40:56.383541: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911301.739796.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911301.739796.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911301.739796.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911301.739796.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:42:28 +0000] \"POST /invocations HTTP/1.1\" 200 19154220 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911348.5407557.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911348.5407557.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:42:28 +0000] \"POST /invocations HTTP/1.1\" 200 19154220 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911348.5407557.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911348.5407557.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-15 00:42:29.921322: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m2020-04-15 00:42:29.921322: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:43:14 +0000] \"POST /invocations HTTP/1.1\" 200 19103055 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911394.9981234.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911394.9981234.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:43:14 +0000] \"POST /invocations HTTP/1.1\" 200 19103055 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911394.9981234.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911394.9981234.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-15 00:43:16.409269: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35m2020-04-15 00:43:16.409269: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911441.2943144.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911441.2943144.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911441.2943144.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911441.2943144.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:44:47 +0000] \"POST /invocations HTTP/1.1\" 200 19165147 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911487.6310062.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911487.6310062.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:44:47 +0000] \"POST /invocations HTTP/1.1\" 200 19165147 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911487.6310062.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911487.6310062.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:45:11 +0000] \"POST /invocations HTTP/1.1\" 200 8532734 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:45:11 +0000] \"POST /invocations HTTP/1.1\" 200 8532734 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:45:11 +0000] \"POST /invocations HTTP/1.1\" 200 8532734 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:45:11 +0000] \"POST /invocations HTTP/1.1\" 200 8532734 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-075178354542/source_separation/batch-transform-output\n"
     ]
    }
   ],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://'+bucket+'/'+common_prefix+'/batch-transform-output')\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Batch Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1.mp3.out\n",
      "input2.mp3.out\n",
      "input3.mp3.out\n",
      "input4.mp3.out\n",
      "input5.mp3.out\n",
      "input6.mp3.out\n",
      "input7.mp3.out\n"
     ]
    }
   ],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "audio_util.clear_folder('source-separation-output/batch-transform-output')\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'source-separation-output/batch-transform-output/output-{}.zip'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-3.zip\n",
      "output-6.zip\n",
      "output-1.zip\n",
      "output-4.zip\n",
      "output-7.zip\n",
      "output-2.zip\n",
      "output-5.zip\n"
     ]
    }
   ],
   "source": [
    "# Extracting files from zip files. \n",
    "audio_util.clear_folder('source-separation-output/extracted')\n",
    "for file in os.listdir('source-separation-output/batch-transform-output'):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile('source-separation-output/batch-transform-output/'+file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('source-separation-output/extracted/'+file.split('.')[0]+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the vocal files and the background sound files.\n",
    "audio_util.clear_folder('source-separation-output/vocals')\n",
    "audio_util.clear_folder('source-separation-output/background')\n",
    "for i, folder in enumerate(sorted(os.listdir('source-separation-output/extracted/'))):\n",
    "    for file in os.listdir('source-separation-output/extracted/' + folder + '/output'):\n",
    "        new_file_name = str(i).zfill(5) + \".wav\"\n",
    "        if \"vocals\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/vocals/vocals' + new_file_name)\n",
    "        elif \"accompaniment\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/background/background' + new_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Vocal Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribe input uploaded to s3://sagemaker-us-east-2-075178354542/transcribe-input\n"
     ]
    }
   ],
   "source": [
    "# Upload the Vocal files onto s3\n",
    "local_vocals_folder = \"source-separation-output/vocals/\"\n",
    "transcribe_input_prefix = \"transcribe-input\"\n",
    "\n",
    "transcribe_input = sagemaker_session.upload_data(local_vocals_folder, key_prefix=transcribe_input_prefix)\n",
    "print(\"Transcribe input uploaded to \" + transcribe_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing: vocals00000.wav\n",
      "Transcribing: vocals00001.wav\n",
      "Transcribing: vocals00002.wav\n",
      "Transcribing: vocals00003.wav\n",
      "Transcribing: vocals00004.wav\n",
      "Transcribing: vocals00005.wav\n",
      "Transcribing: vocals00006.wav\n"
     ]
    }
   ],
   "source": [
    "# Start a transcription job for each file. Add the transcription to finsihed jobs once finished. \n",
    "transcribe = boto3.client('transcribe')\n",
    "output_bucket_name = \"transcribe-output\"\n",
    "audio_util.clear_folder('transcribe-output')\n",
    "uri_prefix = \"https://%s.s3.%s.amazonaws.com/transcribe-input/\" % (sagemaker_session.default_bucket(), boto3.client('s3').get_bucket_location(Bucket=sagemaker_session.default_bucket())['LocationConstraint'])\n",
    "finished_jobs = list()\n",
    "\n",
    "for file in sorted(os.listdir(local_vocals_folder)):\n",
    "\n",
    "    print(\"Transcribing: \" + file)\n",
    "    job_uri = uri_prefix + file\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=file,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='wav',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=file)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "    \n",
    "    api_data = requests.get(url=status['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "    data = api_data.json()\n",
    "    finished_jobs.append(data)\n",
    "    dump_file_name = 'transcribe-output/transcription' + file.split(\".\")[0] + '.json'\n",
    "    # Writing to json files for analysis purposes.\n",
    "    with open(dump_file_name, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    transcribe.delete_transcription_job(TranscriptionJobName=file)\n",
    "    \n",
    "finished_jobs.sort(key=lambda x : x['jobName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Transcribe Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustable Variables:\n",
    "\n",
    "# Short words tend to be transcribed too short. So this manually extends them. \n",
    "extend_word_length_factor = 200 # (percent of total word duration)\n",
    "word_under_x_ms_long = 500 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching the batches back together, generate transcription list from all the batches. \n",
    "transcribe_output_folder = \"transcribe-output/\"\n",
    "offset = 0 # Takes into account that batches are sequential.\n",
    "transcription_list = list()\n",
    "index = 0\n",
    "for file in sorted(os.listdir(transcribe_output_folder)):\n",
    "    transcription_batch = json.load(open(transcribe_output_folder + file, \"r\", encoding=\"utf-8\"))\n",
    "    for map_item in transcription_batch[\"results\"][\"items\"]:\n",
    "        transcribe_object = processing_util.TranscriptionItem(map_item, index, offset)\n",
    "        index += 1\n",
    "        # Skip punctuation\n",
    "        if transcribe_object.is_word():\n",
    "            if transcribe_object.duration() < word_under_x_ms_long:\n",
    "                transcribe_object.end_time += extend_word_length_factor\n",
    "            transcription_list.append(transcribe_object)\n",
    "        # Increase word duration if very short\n",
    "\n",
    "    offset += 30000\n",
    "    \n",
    "# Add the \n",
    "transcribed_song_folder = \"song-transcription/\"\n",
    "audio_util.clear_folder(transcribed_song_folder)\n",
    "with open(transcribed_song_folder + \"transcribed_song.json\", 'w') as outfile:\n",
    "    json.dump([item.to_dict() for item in transcription_list], outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giving Transcriptions to Amazon Polly\n",
    "\n",
    "Amazon Polly is queried for each individual word to allow for easier control of timing and pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_polly(polly_client, word, length, prefix, output_folder):\n",
    "    \n",
    "    ssml = \"\"\"<speak><prosody amazon:max-duration=\"{max_len}ms\">{word}</prosody></speak>\"\"\".format(max_len=str(length), word=word)          \n",
    "    response = polly_client.start_speech_synthesis_task(VoiceId='Joey',\n",
    "                OutputS3BucketName='sagemaker-us-east-2-075178354542',\n",
    "                OutputS3KeyPrefix='polly-output/' + prefix,\n",
    "                OutputFormat='mp3', \n",
    "                TextType = 'ssml',\n",
    "                Text = ssml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polly Queried for: imagine\n",
      "Polly Queried for: there's\n",
      "Polly Queried for: no\n",
      "Polly Queried for: heaven\n",
      "Polly Queried for: It's\n",
      "Polly Queried for: easy\n",
      "Polly Queried for: if\n",
      "Polly Queried for: you\n",
      "Polly Queried for: try\n",
      "Polly Queried for: No\n",
      "Polly Queried for: Hell\n",
      "Polly Queried for: no\n",
      "Polly Queried for: above\n",
      "Polly Queried for: us\n",
      "Polly Queried for: Only\n",
      "Polly Queried for: sky\n",
      "Polly Queried for: Imagine\n",
      "Polly Queried for: all\n",
      "Polly Queried for: the\n",
      "Polly Queried for: people\n",
      "Polly Queried for: with\n",
      "Polly Queried for: today\n",
      "Polly Queried for: it\n",
      "Polly Queried for: isn't\n",
      "Polly Queried for: todo\n",
      "Polly Queried for: nothing\n",
      "Polly Queried for: to\n",
      "Polly Queried for: kill\n",
      "Polly Queried for: No\n",
      "Polly Queried for: religion\n",
      "Polly Queried for: Thio\n",
      "Polly Queried for: Imagine\n",
      "Polly Queried for: all\n",
      "Polly Queried for: the\n",
      "Polly Queried for: bbo\n",
      "Polly Queried for: My\n",
      "Polly Queried for: me\n",
      "Polly Queried for: is\n",
      "Polly Queried for: you\n",
      "Polly Queried for: You\n",
      "Polly Queried for: may\n",
      "Polly Queried for: say\n",
      "Polly Queried for: I'm\n",
      "Polly Queried for: a\n",
      "Polly Queried for: dreamer\n",
      "Polly Queried for: but\n",
      "Polly Queried for: I'm\n",
      "Polly Queried for: not\n",
      "Polly Queried for: a\n",
      "Polly Queried for: real\n",
      "Polly Queried for: war\n",
      "Polly Queried for: I\n",
      "Polly Queried for: hope\n",
      "Polly Queried for: someday\n",
      "Polly Queried for: John\n",
      "Polly Queried for: and\n",
      "Polly Queried for: the\n",
      "Polly Queried for: way\n",
      "Polly Queried for: will\n",
      "Polly Queried for: be\n",
      "Polly Queried for: imagine\n",
      "Polly Queried for: no\n",
      "Polly Queried for: possessions\n",
      "Polly Queried for: I\n",
      "Polly Queried for: wonder\n",
      "Polly Queried for: if\n",
      "Polly Queried for: you\n",
      "Polly Queried for: can\n",
      "Polly Queried for: No\n",
      "Polly Queried for: need\n",
      "Polly Queried for: with\n",
      "Polly Queried for: green\n",
      "Polly Queried for: off\n",
      "Polly Queried for: Brother\n",
      "Polly Queried for: off\n",
      "Polly Queried for: man\n",
      "Polly Queried for: Imagine\n",
      "Polly Queried for: all\n",
      "Polly Queried for: the\n",
      "Polly Queried for: BDO\n",
      "Polly Queried for: Jerry\n",
      "Polly Queried for: No\n",
      "Polly Queried for: we're\n",
      "Polly Queried for: You\n",
      "Polly Queried for: may\n",
      "Polly Queried for: say\n",
      "Polly Queried for: I'm\n",
      "Polly Queried for: a\n",
      "Polly Queried for: dreamer\n",
      "Polly Queried for: but\n",
      "Polly Queried for: I'm\n",
      "Polly Queried for: not\n",
      "Polly Queried for: the\n",
      "Polly Queried for: only\n",
      "Polly Queried for: one\n",
      "Polly Queried for: I\n",
      "Polly Queried for: hope\n",
      "Polly Queried for: someday\n",
      "Polly Queried for: you\n",
      "Polly Queried for: John\n",
      "Polly Queried for: and\n",
      "Polly Queried for: the\n",
      "Polly Queried for: little\n",
      "Polly Queried for: one\n"
     ]
    }
   ],
   "source": [
    "polly_client = boto3.client('polly')\n",
    "polly_output_folder = \"polly-output/\"\n",
    "\n",
    "for transcribe_object in transcription_list:\n",
    "    \n",
    "    response = query_polly(polly_client, transcribe_object.content, transcribe_object.duration(), transcribe_object.index, polly_output_folder)\n",
    "\n",
    "    print(\"Polly Queried for: \" + transcribe_object.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Output from Amazon Polly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved from s3 to repo.\n"
     ]
    }
   ],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"polly-output/\"\n",
    "audio_util.clear_folder(prefix)\n",
    "\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    my_bucket.download_file(prefix+ file_name, prefix + file_name)\n",
    "    \n",
    "print(\"Files moved from s3 to repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continued Steps for Generating the Actual Song\n",
    "\n",
    "Commit the changes and created files to the forked repo. Clone the repo to an Ubuntu machine with python 3. You may have to add some dependencies such as ffmpeg and pydub:\n",
    "\n",
    "* for Ubuntu:\n",
    "```\n",
    "$ sudo apt-get install ffmpeg\n",
    "$ pip install pydub\n",
    "```\n",
    "\n",
    "Then just run main.py from the root of the repo:\n",
    "\n",
    "python main.py\n",
    "\n",
    "The final output after running main.py will show up in the ```final-output``` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull\n",
    "!git add .\n",
    "!git commit -m\"I created small snippets of a song!\"\n",
    "!git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
