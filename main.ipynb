{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git commit -m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudo: apt: command not found\r\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from sagemaker import ModelPackage\n",
    "\n",
    "!sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution role\n",
    "role = get_execution_role()\n",
    "# S3 prefixes\n",
    "common_prefix = \"source_separation\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "# Sagemaker Session\n",
    "sagemaker_session = sage.Session()\n",
    "# Arn for Source Separator Model Package\n",
    "modelpackage_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "#from sagemaker.predictor import csv_serializer\n",
    "\n",
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Batch Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-075178354542/source_separation/batch-inference-input-data\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"input\"\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2020-04-12 06:13:02 +0000] [10] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2020-04-12 06:13:02 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2020-04-12 06:13:02 +0000] [10] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-04-12 06:13:02 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2020-04-12 06:13:02 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-04-12 06:13:02 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2020-04-12 06:13:02 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-12 06:13:46.428785: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:13:46 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:13:46 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672026.7589955.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672026.7589955.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m2020-04-12 06:13:46.428785: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:13:46 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:13:46 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672026.7589955.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672026.7589955.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[32m2020-04-12T06:13:46.721:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:14:32 +0000] \"POST /invocations HTTP/1.1\" 200 19391978 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672072.6487582.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672072.6487582.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:14:32 +0000] \"POST /invocations HTTP/1.1\" 200 19391978 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672072.6487582.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672072.6487582.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-12 06:14:34.025528: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[35m2020-04-12 06:14:34.025528: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m['audio_file_1586672072.6487582.mp3_vocals.wav', 'audio_file_1586672072.6487582.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[35m['audio_file_1586672072.6487582.mp3_vocals.wav', 'audio_file_1586672072.6487582.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:15:18 +0000] \"POST /invocations HTTP/1.1\" 200 19453914 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672118.4082892.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672118.4082892.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:15:18 +0000] \"POST /invocations HTTP/1.1\" 200 19453914 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672118.4082892.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672118.4082892.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:16:04 +0000] \"POST /invocations HTTP/1.1\" 200 19436044 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672164.2195466.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:16:04 +0000] \"POST /invocations HTTP/1.1\" 200 19436044 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672164.2195466.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672164.2195466.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672164.2195466.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:16:49 +0000] \"POST /invocations HTTP/1.1\" 200 19435235 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672209.9600818.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672209.9600818.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:16:49 +0000] \"POST /invocations HTTP/1.1\" 200 19435235 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672209.9600818.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672209.9600818.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:17:35 +0000] \"POST /invocations HTTP/1.1\" 200 19477349 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672255.5786407.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672255.5786407.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:17:35 +0000] \"POST /invocations HTTP/1.1\" 200 19477349 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672255.5786407.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672255.5786407.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:18:21 +0000] \"POST /invocations HTTP/1.1\" 200 19460915 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672301.1194854.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672301.1194854.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:18:21 +0000] \"POST /invocations HTTP/1.1\" 200 19460915 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672301.1194854.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672301.1194854.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:19:06 +0000] \"POST /invocations HTTP/1.1\" 200 19459102 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672346.7678034.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672346.7678034.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:19:06 +0000] \"POST /invocations HTTP/1.1\" 200 19459102 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672346.7678034.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672346.7678034.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:19:52 +0000] \"POST /invocations HTTP/1.1\" 200 19035684 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586672392.642487.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586672392.642487.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:19:52 +0000] \"POST /invocations HTTP/1.1\" 200 19035684 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586672392.642487.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586672392.642487.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:20:05 +0000] \"POST /invocations HTTP/1.1\" 200 4379039 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:20:05 +0000] \"POST /invocations HTTP/1.1\" 200 4379039 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Apr/2020:06:20:05 +0000] \"POST /invocations HTTP/1.1\" 200 4379039 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [12/Apr/2020:06:20:05 +0000] \"POST /invocations HTTP/1.1\" 200 4379039 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-075178354542/source_separation/batch-transform-output\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import uuid\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://'+bucket+'/'+common_prefix+'/batch-transform-output')\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1.mp3.out\n",
      "input2.mp3.out\n",
      "input3.mp3.out\n",
      "input4.mp3.out\n",
      "input5.mp3.out\n",
      "input6.mp3.out\n",
      "input7.mp3.out\n",
      "input8.mp3.out\n",
      "input9.mp3.out\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'data/batch-transform-output/output-{}.zip'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-3.zip\n",
      "output-6.zip\n",
      "output-8.zip\n",
      "output-9.zip\n",
      "output-1.zip\n",
      "output-4.zip\n",
      "output-7.zip\n",
      "output-2.zip\n",
      "output-5.zip\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data/batch-transform-output'):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile('data/batch-transform-output/'+file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data/batch-transform-output/'+file.split('.')[0]+'/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
