{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing pip dependencies.\n",
    "!pip install pydub\n",
    "!pip install crepe\n",
    "!pip install tqdm\n",
    "# Installing conda dependencies\n",
    "!conda install -c conda-forge ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os\n",
    "import json \n",
    "import uuid\n",
    "import requests\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Installing src dependency.\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import processing_util\n",
    "import audio_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://aws.amazon.com/marketplace/pp/prodview-23n4vi2zw67we to get the arn for the model package. \n",
    "\n",
    "***YOU NEED TO REPLACE THE STRING FOR THE ```modelpackage_arn``` VARIABLE WITH YOUR OWN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution role\n",
    "role = get_execution_role()\n",
    "# S3 prefixes\n",
    "common_prefix = \"source_separation\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "# Sagemaker Session\n",
    "sagemaker_session = sage.Session()\n",
    "# Arn for Quantphi Source Separator Model Package\n",
    "modelpackage_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Corresponding IAM Role, add the following policies:\n",
    "\n",
    "* AmazonTranscribeFullAccess\n",
    "* AWSMarketplaceManageSubscriptions\n",
    "* AmazonPollyFullAccess\n",
    "* AmazonSageMakerFullAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Song for Input\n",
    "\n",
    "Below here just choose what song you want to do the demo with by replacing the current song specified by the input_song variable with one of the songs below:\n",
    "\n",
    "* ```imagine-john_lennon```\n",
    "* ```toosie_slide-drake```\n",
    "* ```just_the_way_you_are-bruno_mars```\n",
    "* ```love_yourself-justin_bieber```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_song = \"love_yourself-justin_bieber\"\n",
    "batch_input_folder = \"source-separation-input/\" + input_song + \"/\"\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(batch_input_folder, key_prefix=batch_inference_input_prefix)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Batch Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://'+bucket+'/'+common_prefix+'/batch-transform-output')\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "time.sleep(5)\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Batch Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "processing_util.clear_folder('source-separation-output/batch-transform-output')\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'source-separation-output/batch-transform-output/output-{}.zip'.format(i))\n",
    "    \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files from zip files. \n",
    "processing_util.clear_folder('source-separation-output/extracted')\n",
    "for file in os.listdir('source-separation-output/batch-transform-output'):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile('source-separation-output/batch-transform-output/'+file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('source-separation-output/extracted/'+file.split('.')[0]+'/')\n",
    "        \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the vocal files and the background sound files.\n",
    "processing_util.clear_folder('source-separation-output/vocals')\n",
    "processing_util.clear_folder('source-separation-output/background')\n",
    "for i, folder in enumerate(sorted(os.listdir('source-separation-output/extracted/'))):\n",
    "    for file in os.listdir('source-separation-output/extracted/' + folder + '/output'):\n",
    "        new_file_name = str(i).zfill(5) + \".wav\"\n",
    "        if \"vocals\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/vocals/vocals' + new_file_name)\n",
    "        elif \"accompaniment\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/background/background' + new_file_name)\n",
    "            \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Vocal Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the Vocal files onto s3\n",
    "local_vocals_folder = \"source-separation-output/vocals/\"\n",
    "transcribe_input_prefix = \"transcribe-input\"\n",
    "\n",
    "transcribe_input = sagemaker_session.upload_data(local_vocals_folder, key_prefix=transcribe_input_prefix)\n",
    "print(\"Transcribe input uploaded to \" + transcribe_input)\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a transcription job for each file. Add the transcription to finsihed jobs once finished. \n",
    "transcribe = boto3.client('transcribe')\n",
    "output_bucket_name = \"transcribe-output\"\n",
    "processing_util.clear_folder('transcribe-output')\n",
    "uri_prefix = \"https://%s.s3.%s.amazonaws.com/transcribe-input/\" % (sagemaker_session.default_bucket(), boto3.client('s3').get_bucket_location(Bucket=sagemaker_session.default_bucket())['LocationConstraint'])\n",
    "finished_jobs = list()\n",
    "\n",
    "for file in sorted(os.listdir(local_vocals_folder)):\n",
    "\n",
    "    print(\"Transcribing: \" + file)\n",
    "    job_uri = uri_prefix + file\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=file,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='wav',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=file)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "    time.sleep(3)\n",
    "    api_data = requests.get(url=status['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "    data = api_data.json()\n",
    "    finished_jobs.append(data)\n",
    "    dump_file_name = 'transcribe-output/transcription' + file.split(\".\")[0] + '.json'\n",
    "    # Writing to json files for analysis purposes.\n",
    "    with open(dump_file_name, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    transcribe.delete_transcription_job(TranscriptionJobName=file)\n",
    "    \n",
    "finished_jobs.sort(key=lambda x : x['jobName'])\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Transcribe Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short words tend to be transcribed too short. So this manually extends them. \n",
    "extend_word_length_factor = 200 # (percent of total word duration)\n",
    "word_under_x_ms_long = 500 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching the batches back together, generate transcription list from all the batches. \n",
    "transcribe_output_folder = \"transcribe-output/\"\n",
    "offset = 0 # Takes into account that batches are sequential.\n",
    "transcription_list = list()\n",
    "index = 0\n",
    "for file in sorted(os.listdir(transcribe_output_folder)):\n",
    "    transcription_batch = json.load(open(transcribe_output_folder + file, \"r\", encoding=\"utf-8\"))\n",
    "    for map_item in transcription_batch[\"results\"][\"items\"]:\n",
    "        transcribe_object = processing_util.TranscriptionItem(map_item, index, offset)\n",
    "        # Skip punctuation\n",
    "        if transcribe_object.is_word():\n",
    "            # Increase word duration if very short\n",
    "            if transcribe_object.duration() < word_under_x_ms_long:\n",
    "                transcribe_object.end_time += extend_word_length_factor\n",
    "            transcription_list.append(transcribe_object)\n",
    "            index += 1\n",
    "\n",
    "    offset += 30000\n",
    "    \n",
    "# Compile the entire song transcription into one file.\n",
    "transcribed_song_folder = \"song-transcription/\"\n",
    "processing_util.clear_folder(transcribed_song_folder)\n",
    "with open(transcribed_song_folder + \"transcribed_song.json\", 'w') as outfile:\n",
    "    json.dump([item.to_dict() for item in transcription_list], outfile, indent=4)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giving Transcriptions to Amazon Polly\n",
    "\n",
    "Amazon Polly is queried for each individual word to allow for easier control of timing and pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_polly(polly_client, word, length, prefix, output_folder):\n",
    "    \n",
    "    ssml = \"\"\"<speak><prosody amazon:max-duration=\"{max_len}ms\">{word}</prosody></speak>\"\"\".format(max_len=str(length), word=word)          \n",
    "    response = polly_client.start_speech_synthesis_task(VoiceId='Justin',\n",
    "                OutputS3BucketName='sagemaker-us-east-2-075178354542',\n",
    "                OutputS3KeyPrefix='polly-output/' + prefix,\n",
    "                OutputFormat='mp3', \n",
    "                TextType = 'ssml',\n",
    "                Text = ssml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "polly_client = boto3.client('polly')\n",
    "polly_output_folder = \"polly-output/\"\n",
    "\n",
    "print(\"Generating audio file for each word...\")\n",
    "for transcribe_object in tqdm(transcription_list):\n",
    "    \n",
    "    response = query_polly(polly_client, transcribe_object.content, transcribe_object.duration(), transcribe_object.index, polly_output_folder)\n",
    "    \n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Output from Amazon Polly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved from s3 to repo.\n"
     ]
    }
   ],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"polly-output/\"\n",
    "processing_util.clear_folder(prefix)\n",
    "\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    my_bucket.download_file(prefix+ file_name, prefix + file_name)\n",
    "\n",
    "time.sleep(5)\n",
    "print(\"Files moved from s3 to repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import processing_util\n",
    "import audio_util\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "from IPython.utils import io\n",
    "\n",
    "POLLY_OUTPUT_FOLDER = \"polly-output/\"\n",
    "BACKGROUND_FOLDER = \"source-separation-output/background/\"\n",
    "FINAL_OUTPUT_FOLDER = \"final-output/\"\n",
    "SONG_TRANSCRIPTION_PATH = \"song-transcription/transcribed_song.json\"\n",
    "BATCH_LENGTH = 30000 # m\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Generate Background\n",
    "background_mp3_files = [BACKGROUND_FOLDER + s for s in sorted(os.listdir(BACKGROUND_FOLDER))]\n",
    "background_mp3 = audio_util.interpret_polly_output_file(background_mp3_files[0])\n",
    "background_mp3_files.pop(0)\n",
    "for fname in tqdm(background_mp3_files):\n",
    "    background_mp3 += audio_util.interpret_polly_output_file(fname)\n",
    "background_mp3.export(FINAL_OUTPUT_FOLDER + \"background.mp3\", format=\"mp3\")\n",
    "\n",
    "# Generate Vocals\n",
    "polly_output = sorted(os.listdir(POLLY_OUTPUT_FOLDER))\n",
    "song_transcription = json.load(open(SONG_TRANSCRIPTION_PATH, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "vocal_mp3 = audio_util.get_silence(1)\n",
    "expected_start_time = 0\n",
    "\n",
    "for transcription_item, mp3_file in tqdm(list(zip(song_transcription, polly_output))):\n",
    "    if expected_start_time < transcription_item[\"start_time\"]:\n",
    "        vocal_mp3 += audio_util.get_silence(transcription_item[\"start_time\"] - expected_start_time)\n",
    "        expected_start_time = transcription_item[\"start_time\"]\n",
    "\n",
    "    assert(mp3_file.startswith(transcription_item[\"index\"]))\n",
    "    audio_clip = audio_util.interpret_polly_output_file(POLLY_OUTPUT_FOLDER + mp3_file)\n",
    "\n",
    "# Version 1.1: No pitch modification, more stable\n",
    "#     vocal_mp3 += audio_clip\n",
    "#     expected_start_time += len(audio_clip)\n",
    "# Version 2.2: Includes pitch modification\n",
    "    corrected_audio_clip = None\n",
    "    if transcription_item[\"end_time\"] - transcription_item[\"start_time\"] > 50:\n",
    "        with io.capture_output() as captured:\n",
    "            corrected_audio_clip = audio_util.pitch_correction(audio_clip, transcription_item[\"start_time\"], transcription_item[\"end_time\"], \"temp/\")\n",
    "    if corrected_audio_clip:\n",
    "        vocal_mp3 += corrected_audio_clip\n",
    "        expected_start_time += len(corrected_audio_clip)\n",
    "    else:\n",
    "        vocal_mp3 += audio_clip\n",
    "        expected_start_time += len(audio_clip)\n",
    "\n",
    "vocal_mp3.export(FINAL_OUTPUT_FOLDER + \"vocals.mp3\", format=\"mp3\")\n",
    "\n",
    "\n",
    "print(\"Overlaying the vocals with the accompaniment and generating the final audio file...\")\n",
    "final_audio = background_mp3.overlay(vocal_mp3)\n",
    "final_audio.export(FINAL_OUTPUT_FOLDER + \"final_audio.mp3\", format=\"mp3\")\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to the Song Cover :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio('final-output/background.mp3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
