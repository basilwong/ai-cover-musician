{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.23.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: crepe in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.0.11)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from crepe) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from crepe) (1.18.2)\n",
      "Requirement already satisfied: h5py<3.0.0,>=2.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from crepe) (2.8.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from crepe) (2.3.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from crepe) (1.1.0)\n",
      "Requirement already satisfied: resampy<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from crepe) (0.2.2)\n",
      "Requirement already satisfied: hmmlearn<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from crepe) (0.2.3)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from crepe) (0.20.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.0->crepe) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.0->crepe) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.0->crepe) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.0->crepe) (2.7.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py<3.0.0,>=2.7.0->crepe) (1.11.0)\n",
      "Requirement already satisfied: numba>=0.32 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from resampy<0.3.0,>=0.2.0->crepe) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->crepe) (39.1.0)\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from numba>=0.32->resampy<0.3.0,>=0.2.0->crepe) (0.23.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.45.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.6.1)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.18.2)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "\u001b[31mtensorboard 1.14.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: wrapt, tensorflow-estimator, absl-py, markdown, grpcio, tensorboard, keras-preprocessing, tensorflow\n",
      "  Found existing installation: wrapt 1.10.11\n",
      "\u001b[31mCannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing pip dependencies.\n",
    "!pip install pydub\n",
    "!pip install crepe\n",
    "!pip install tqdm\n",
    "!pip install tensorflow\n",
    "# Installing conda dependencies\n",
    "# !conda install -c conda-forge ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os\n",
    "import json \n",
    "import uuid\n",
    "import requests\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Installing src dependency.\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import processing_util\n",
    "import audio_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://aws.amazon.com/marketplace/pp/prodview-23n4vi2zw67we to get the arn for the model package. \n",
    "\n",
    "***YOU NEED TO REPLACE THE STRING FOR THE ```modelpackage_arn``` VARIABLE WITH YOUR OWN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution role\n",
    "role = get_execution_role()\n",
    "# S3 prefixes\n",
    "common_prefix = \"source_separation\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "# Sagemaker Session\n",
    "sagemaker_session = sage.Session()\n",
    "# Arn for Quantphi Source Separator Model Package\n",
    "modelpackage_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Corresponding IAM Role, add the following policies:\n",
    "\n",
    "* AmazonTranscribeFullAccess\n",
    "* AWSMarketplaceManageSubscriptions\n",
    "* AmazonPollyFullAccess\n",
    "* AmazonSageMakerFullAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Song for Input\n",
    "\n",
    "Below here just choose what song you want to do the demo with by replacing the current song specified by the input_song variable with one of the songs below:\n",
    "\n",
    "* ```imagine-john_lennon```\n",
    "* ```toosie_slide-drake```\n",
    "* ```just_the_way_you_are-bruno_mars```\n",
    "* ```love_yourself-justin_bieber```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_song = \"love_yourself-justin_bieber\"\n",
    "batch_input_folder = \"source-separation-input/\" + input_song + \"/\"\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(batch_input_folder, key_prefix=batch_inference_input_prefix)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Batch Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://'+bucket+'/'+common_prefix+'/batch-transform-output')\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "time.sleep(5)\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Batch Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "processing_util.clear_folder('source-separation-output/batch-transform-output')\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'source-separation-output/batch-transform-output/output-{}.zip'.format(i))\n",
    "    \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files from zip files. \n",
    "processing_util.clear_folder('source-separation-output/extracted')\n",
    "for file in os.listdir('source-separation-output/batch-transform-output'):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile('source-separation-output/batch-transform-output/'+file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('source-separation-output/extracted/'+file.split('.')[0]+'/')\n",
    "        \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the vocal files and the background sound files.\n",
    "processing_util.clear_folder('source-separation-output/vocals')\n",
    "processing_util.clear_folder('source-separation-output/background')\n",
    "for i, folder in enumerate(sorted(os.listdir('source-separation-output/extracted/'))):\n",
    "    for file in os.listdir('source-separation-output/extracted/' + folder + '/output'):\n",
    "        new_file_name = str(i).zfill(5) + \".wav\"\n",
    "        if \"vocals\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/vocals/vocals' + new_file_name)\n",
    "        elif \"accompaniment\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/background/background' + new_file_name)\n",
    "            \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Vocal Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the Vocal files onto s3\n",
    "local_vocals_folder = \"source-separation-output/vocals/\"\n",
    "transcribe_input_prefix = \"transcribe-input\"\n",
    "\n",
    "transcribe_input = sagemaker_session.upload_data(local_vocals_folder, key_prefix=transcribe_input_prefix)\n",
    "print(\"Transcribe input uploaded to \" + transcribe_input)\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a transcription job for each file. Add the transcription to finsihed jobs once finished. \n",
    "transcribe = boto3.client('transcribe')\n",
    "output_bucket_name = \"transcribe-output\"\n",
    "processing_util.clear_folder('transcribe-output')\n",
    "uri_prefix = \"https://%s.s3.%s.amazonaws.com/transcribe-input/\" % (sagemaker_session.default_bucket(), boto3.client('s3').get_bucket_location(Bucket=sagemaker_session.default_bucket())['LocationConstraint'])\n",
    "finished_jobs = list()\n",
    "\n",
    "for file in sorted(os.listdir(local_vocals_folder)):\n",
    "\n",
    "    print(\"Transcribing: \" + file)\n",
    "    job_uri = uri_prefix + file\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=file,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='wav',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=file)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "    time.sleep(3)\n",
    "    api_data = requests.get(url=status['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "    data = api_data.json()\n",
    "    finished_jobs.append(data)\n",
    "    dump_file_name = 'transcribe-output/transcription' + file.split(\".\")[0] + '.json'\n",
    "    # Writing to json files for analysis purposes.\n",
    "    with open(dump_file_name, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    transcribe.delete_transcription_job(TranscriptionJobName=file)\n",
    "    \n",
    "finished_jobs.sort(key=lambda x : x['jobName'])\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Transcribe Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustable Variables:\n",
    "\n",
    "# Short words tend to be transcribed too short. So this manually extends them. \n",
    "extend_word_length_factor = 200 # (percent of total word duration)\n",
    "word_under_x_ms_long = 500 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching the batches back together, generate transcription list from all the batches. \n",
    "transcribe_output_folder = \"transcribe-output/\"\n",
    "offset = 0 # Takes into account that batches are sequential.\n",
    "transcription_list = list()\n",
    "index = 0\n",
    "for file in sorted(os.listdir(transcribe_output_folder)):\n",
    "    transcription_batch = json.load(open(transcribe_output_folder + file, \"r\", encoding=\"utf-8\"))\n",
    "    for map_item in transcription_batch[\"results\"][\"items\"]:\n",
    "        transcribe_object = processing_util.TranscriptionItem(map_item, index, offset)\n",
    "        index += 1\n",
    "        # Skip punctuation\n",
    "        if transcribe_object.is_word():\n",
    "            if transcribe_object.duration() < word_under_x_ms_long:\n",
    "                transcribe_object.end_time += extend_word_length_factor\n",
    "            transcription_list.append(transcribe_object)\n",
    "        # Increase word duration if very short\n",
    "\n",
    "    offset += 30000\n",
    "    \n",
    "# Add the \n",
    "transcribed_song_folder = \"song-transcription/\"\n",
    "processing_util.clear_folder(transcribed_song_folder)\n",
    "with open(transcribed_song_folder + \"transcribed_song.json\", 'w') as outfile:\n",
    "    json.dump([item.to_dict() for item in transcription_list], outfile, indent=4)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giving Transcriptions to Amazon Polly\n",
    "\n",
    "Amazon Polly is queried for each individual word to allow for easier control of timing and pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_polly(polly_client, word, length, prefix, output_folder):\n",
    "    \n",
    "    ssml = \"\"\"<speak><prosody amazon:max-duration=\"{max_len}ms\">{word}</prosody></speak>\"\"\".format(max_len=str(length), word=word)          \n",
    "    response = polly_client.start_speech_synthesis_task(VoiceId='Justin',\n",
    "                OutputS3BucketName='sagemaker-us-east-2-075178354542',\n",
    "                OutputS3KeyPrefix='polly-output/' + prefix,\n",
    "                OutputFormat='mp3', \n",
    "                TextType = 'ssml',\n",
    "                Text = ssml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371/371 [00:36<00:00, 10.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "polly_client = boto3.client('polly')\n",
    "polly_output_folder = \"polly-output/\"\n",
    "\n",
    "print(\"Generating audio file for each word...\")\n",
    "for transcribe_object in tqdm(transcription_list):\n",
    "    \n",
    "    response = query_polly(polly_client, transcribe_object.content, transcribe_object.duration(), transcribe_object.index, polly_output_folder)\n",
    "    \n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Output from Amazon Polly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"polly-output/\"\n",
    "processing_util.clear_folder(prefix)\n",
    "\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    my_bucket.download_file(prefix+ file_name, prefix + file_name)\n",
    "\n",
    "time.sleep(5)\n",
    "print(\"Files moved from s3 to repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  1.77it/s]\n",
      "  0%|          | 0/371 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.layers'; 'tensorflow.keras' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-99c2b8edf8ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mcorrected_audio_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtranscription_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"end_time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtranscription_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start_time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mcorrected_audio_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpitch_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscription_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscription_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"end_time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"temp/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcorrected_audio_clip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mvocal_mp3\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrected_audio_clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/ai-cover-musician/src/audio_util.py\u001b[0m in \u001b[0;36mpitch_correction\u001b[0;34m(audio_segment, start_time, end_time, temp_folder)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpitch_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mpitch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_pitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mpitch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_pitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_original_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpitch1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpitch2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/ai-cover-musician/src/audio_util.py\u001b[0m in \u001b[0;36mdetermine_pitch\u001b[0;34m(audio_segment, temp_folder)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#     sys.stdout = open(os.devnull, 'w')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrepe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviterbi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m#     sys.stdout = sys.__stdout__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnote_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/crepe/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(audio, sr, model_capacity, viterbi, center, step_size, verbose)\u001b[0m\n\u001b[1;32m    255\u001b[0m     activation = get_activation(audio, sr, model_capacity=model_capacity,\n\u001b[1;32m    256\u001b[0m                                 \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                                 verbose=verbose)\n\u001b[0m\u001b[1;32m    258\u001b[0m     \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/crepe/core.py\u001b[0m in \u001b[0;36mget_activation\u001b[0;34m(audio, sr, model_capacity, center, step_size, verbose)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mraw\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_and_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_capacity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/crepe/core.py\u001b[0m in \u001b[0;36mbuild_and_load_model\u001b[0;34m(model_capacity)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrained\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers'; 'tensorflow.keras' is not a package"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import processing_util\n",
    "import audio_util\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "POLLY_OUTPUT_FOLDER = \"polly-output/\"\n",
    "BACKGROUND_FOLDER = \"source-separation-output/background/\"\n",
    "FINAL_OUTPUT_FOLDER = \"final-output/\"\n",
    "SONG_TRANSCRIPTION_PATH = \"song-transcription/transcribed_song.json\"\n",
    "BATCH_LENGTH = 30000 # m\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Generate Background\n",
    "background_mp3_files = [BACKGROUND_FOLDER + s for s in sorted(os.listdir(BACKGROUND_FOLDER))]\n",
    "background_mp3 = audio_util.interpret_polly_output_file(background_mp3_files[0])\n",
    "background_mp3_files.pop(0)\n",
    "for fname in tqdm(background_mp3_files):\n",
    "    background_mp3 += audio_util.interpret_polly_output_file(fname)\n",
    "background_mp3.export(FINAL_OUTPUT_FOLDER + \"background.mp3\", format=\"mp3\")\n",
    "\n",
    "# Generate Vocals\n",
    "polly_output = sorted(os.listdir(POLLY_OUTPUT_FOLDER))\n",
    "song_transcription = json.load(open(SONG_TRANSCRIPTION_PATH, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "vocal_mp3 = audio_util.get_silence(1)\n",
    "expected_start_time = 0\n",
    "\n",
    "for transcription_item, mp3_file in tqdm(list(zip(song_transcription, polly_output))):\n",
    "    if expected_start_time < transcription_item[\"start_time\"]:\n",
    "        vocal_mp3 += audio_util.get_silence(transcription_item[\"start_time\"] - expected_start_time)\n",
    "        expected_start_time = transcription_item[\"start_time\"]\n",
    "\n",
    "    assert(mp3_file.startswith(transcription_item[\"index\"]))\n",
    "    audio_clip = audio_util.interpret_polly_output_file(POLLY_OUTPUT_FOLDER + mp3_file)\n",
    "\n",
    "# Version 1.1: No pitch modification, more stable\n",
    "#     vocal_mp3 += audio_clip\n",
    "#     expected_start_time += len(audio_clip)\n",
    "# Version 2.1: Includes pitch modification\n",
    "    corrected_audio_clip = None\n",
    "    if transcription_item[\"end_time\"] - transcription_item[\"start_time\"] > 50:\n",
    "        corrected_audio_clip = audio_util.pitch_correction(audio_clip, transcription_item[\"start_time\"], transcription_item[\"end_time\"], \"temp/\")\n",
    "    if corrected_audio_clip:\n",
    "        vocal_mp3 += corrected_audio_clip\n",
    "        expected_start_time += len(corrected_audio_clip)\n",
    "    else:\n",
    "        vocal_mp3 += audio_clip\n",
    "        expected_start_time += len(audio_clip)\n",
    "\n",
    "vocal_mp3.export(FINAL_OUTPUT_FOLDER + \"vocals.mp3\", format=\"mp3\")\n",
    "\n",
    "\n",
    "print(\"Overlaying the vocals with the accompaniment and generating the final audio file...\")\n",
    "final_audio = background_mp3.overlay(vocal_mp3)\n",
    "final_audio.export(FINAL_OUTPUT_FOLDER + \"final_audio.mp3\", format=\"mp3\")\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to the Song Cover :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'final-output/vocals.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-a65287af51cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mipd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"final-output/vocals.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m_make_wav\u001b[0;34m(self, data, rate)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mnchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'final-output/vocals.mp3'"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(\"final-output/vocals.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b50dc25ae716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_original_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m34260.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35000.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maudio_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetermine_pitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"temp/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/ai-cover-musician/src/audio_util.py\u001b[0m in \u001b[0;36mdetermine_pitch\u001b[0;34m(audio_segment, temp_folder)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#     sys.stdout = open(os.devnull, 'w')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrepe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviterbi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m#     sys.stdout = sys.__stdout__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnote_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/crepe/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(audio, sr, model_capacity, viterbi, center, step_size, verbose)\u001b[0m\n\u001b[1;32m    255\u001b[0m     activation = get_activation(audio, sr, model_capacity=model_capacity,\n\u001b[1;32m    256\u001b[0m                                 \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                                 verbose=verbose)\n\u001b[0m\u001b[1;32m    258\u001b[0m     \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/crepe/core.py\u001b[0m in \u001b[0;36mget_activation\u001b[0;34m(audio, sr, model_capacity, center, step_size, verbose)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mraw\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_and_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_capacity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/crepe/core.py\u001b[0m in \u001b[0;36mbuild_and_load_model\u001b[0;34m(model_capacity)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrained\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "x = audio_util.get_original_sample(34260.0, 35000.0)\n",
    "audio_util.determine_pitch(x, \"temp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m\"new notebook that fulfills the requirements\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
