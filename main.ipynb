{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing pip dependencies.\n",
    "!pip install pydub\n",
    "!pip install crepe\n",
    "!pip install tqdm\n",
    "# Installing conda dependencies\n",
    "!conda install -c conda-forge ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os\n",
    "import json \n",
    "import uuid\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Installing src dependency.\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "import processing_util\n",
    "import audio_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://aws.amazon.com/marketplace/pp/prodview-23n4vi2zw67we to get the arn for the model package. \n",
    "\n",
    "***YOU NEED TO REPLACE THE STRING FOR THE ```modelpackage_arn``` VARIABLE WITH YOUR OWN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution role\n",
    "role = get_execution_role()\n",
    "# Sagemaker Session\n",
    "sagemaker_session = sage.Session()\n",
    "# S3\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "my_bucket = s3.Bucket(bucket_name)\n",
    "bucket_client = boto3.client('s3')\n",
    "# Arn for Quantphi Source Separator Model Package\n",
    "modelpackage_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Corresponding IAM Role, add the following policies:\n",
    "\n",
    "* AmazonTranscribeFullAccess\n",
    "* AWSMarketplaceManageSubscriptions\n",
    "* AmazonPollyFullAccess\n",
    "* AmazonSageMakerFullAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Song for Input\n",
    "\n",
    "Below here just choose what song you want to do the demo with by replacing the current song specified by the input_song variable with one of the songs below:\n",
    "\n",
    "* ```imagine-john_lennon```\n",
    "* ```toosie_slide-drake```\n",
    "* ```just_the_way_you_are-bruno_mars```\n",
    "* ```love_yourself-justin_bieber```\n",
    "* ```savage-megan_thee_stallion```\n",
    "* ```crazy_in_love-sofia-karlberg```\n",
    "\n",
    "*Note that you can add a custom input by uploading an mp3 file to the ```archive/songs/``` directory and adding the name of the mp3 file to the ```input_song``` variable.*\n",
    "\n",
    "You can also choose the corresponding voice id from Amazon Polly which will be used to cover the song:\n",
    "\n",
    "* ```Joey```\n",
    "* ```Joanna```\n",
    "* ```Matthew```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "input_song = \"toosie_slide-drake\"\n",
    "voice_id = \"Joey\"\n",
    "\n",
    "# Take the mp3 and split it into 30 second segments.  \n",
    "input_song = input_song if input_song.endswith(\".mp3\") else input_song + \".mp3\"\n",
    "batch_input_folder = \"source-separation-input\"\n",
    "audio_util.split_mp3(\"./archive/songs/\" + input_song, batch_input_folder + \"/\")\n",
    "# Save all segments in s3 bucket for batch. \n",
    "processing_util.clear_s3_folder(my_bucket, bucket_client, batch_input_folder)\n",
    "transform_input = sagemaker_session.upload_data(batch_input_folder + \"/\", key_prefix=batch_input_folder)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Batch Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output_folder = \"source-separation-output\"\n",
    "\n",
    "processing_util.clear_s3_folder(my_bucket, bucket_client, batch_output_folder + \"/\")\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://' + bucket_name + \"/\" + batch_output_folder)\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "time.sleep(5)\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Batch Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading files from s3.\n",
    "i = 0\n",
    "processing_util.clear_folder(batch_output_folder + \"/\")\n",
    "for object_summary in my_bucket.objects.filter(Prefix=batch_output_folder):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(batch_output_folder + \"/\" + file_name, batch_output_folder + '/output-{}.zip'.format(i))\n",
    "    \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files from zip files. \n",
    "extraction_folder = 'source-separation-output-extracted/'\n",
    "processing_util.clear_folder(extraction_folder)\n",
    "for file in os.listdir(batch_output_folder):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile(batch_output_folder + \"/\" + file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extraction_folder+file.split('.')[0]+'/')\n",
    "        \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the vocal files and the background sound files.\n",
    "isolated_vocals_folder = \"isolated-vocals/\"\n",
    "isolated_background_folder = \"isolated-background/\"\n",
    "\n",
    "processing_util.clear_folder(isolated_vocals_folder)\n",
    "processing_util.clear_folder(isolated_background_folder)\n",
    "for i, folder in enumerate(sorted(os.listdir(extraction_folder))):\n",
    "    for file in os.listdir(extraction_folder + folder + '/output'):\n",
    "        new_file_name = str(i).zfill(5) + \".wav\"\n",
    "        if \"vocals\" in file:\n",
    "            os.rename(extraction_folder + folder + '/output/' + file, isolated_vocals_folder + 'vocals' + new_file_name)\n",
    "        elif \"accompaniment\" in file:\n",
    "            os.rename(extraction_folder + folder + '/output/' + file, isolated_background_folder + 'background' + new_file_name)\n",
    "            \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Vocal Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the Vocal files onto s3\n",
    "transcribe_input_prefix = \"transcribe-input\"\n",
    "\n",
    "processing_util.clear_s3_folder(my_bucket, bucket_client, transcribe_input_prefix + \"/\")\n",
    "transcribe_input = sagemaker_session.upload_data(isolated_vocals_folder, key_prefix=transcribe_input_prefix)\n",
    "print(\"Transcribe input uploaded to \" + transcribe_input)\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a transcription job for each file. Add the transcription to finsihed jobs once finished. \n",
    "transcribe = boto3.client('transcribe')\n",
    "output_bucket_name = \"transcribe-output\"\n",
    "processing_util.clear_folder('transcribe-output')\n",
    "uri_prefix = \"https://%s.s3.%s.amazonaws.com/transcribe-input/\" % (sagemaker_session.default_bucket(), boto3.client('s3').get_bucket_location(Bucket=sagemaker_session.default_bucket())['LocationConstraint'])\n",
    "finished_jobs = list()\n",
    "\n",
    "for file in sorted(os.listdir(isolated_vocals_folder)):\n",
    "\n",
    "    print(\"Transcribing: \" + file)\n",
    "    job_uri = uri_prefix + file\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=file,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='wav',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=file)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "    time.sleep(3)\n",
    "    api_data = requests.get(url=status['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "    data = api_data.json()\n",
    "    finished_jobs.append(data)\n",
    "    dump_file_name = 'transcribe-output/transcription' + file.split(\".\")[0] + '.json'\n",
    "    # Writing to json files for analysis purposes.\n",
    "    with open(dump_file_name, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    transcribe.delete_transcription_job(TranscriptionJobName=file)\n",
    "    \n",
    "finished_jobs.sort(key=lambda x : x['jobName'])\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Transcribe Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short words tend to be transcribed too short. So this manually extends them. \n",
    "extend_word_length_factor = 100 \n",
    "word_under_x_ms_long = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching the batches back together, generate transcription list from all the batches. \n",
    "transcribe_output_folder = \"transcribe-output/\"\n",
    "offset = 0 # Takes into account that batches are sequential.\n",
    "transcription_list = list()\n",
    "index = 0\n",
    "for file in sorted(os.listdir(transcribe_output_folder)):\n",
    "    transcription_batch = json.load(open(transcribe_output_folder + file, \"r\", encoding=\"utf-8\"))\n",
    "    for map_item in transcription_batch[\"results\"][\"items\"]:\n",
    "        transcribe_object = processing_util.TranscriptionItem(map_item, index, offset)\n",
    "        # Skip punctuation\n",
    "        if transcribe_object.is_word():\n",
    "            # Increase word duration if very short\n",
    "            if transcribe_object.duration() < word_under_x_ms_long:\n",
    "                transcribe_object.end_time += extend_word_length_factor\n",
    "            transcription_list.append(transcribe_object)\n",
    "            index += 1\n",
    "\n",
    "    offset += 30000\n",
    "    \n",
    "# Compile the entire song transcription into one file.\n",
    "transcribed_song_folder = \"song-transcription/\"\n",
    "processing_util.clear_folder(transcribed_song_folder)\n",
    "with open(transcribed_song_folder + \"transcribed_song.json\", 'w') as outfile:\n",
    "    json.dump([item.to_dict() for item in transcription_list], outfile, indent=4)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giving Transcriptions to Amazon Polly\n",
    "\n",
    "Amazon Polly is queried for each individual word to allow for easier control of timing and pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_polly(polly_client, word, length, bucket_prefix, output_folder, pitch_mod, voice_id='Joey'):\n",
    "    \n",
    "    if pitch_mod > 12 or pitch_mod < -12:\n",
    "        pitch_mod_factor = 0\n",
    "    else:\n",
    "        pitch_mod_factor = ((2**(1.0 * pitch_mod / 12.0)) - 1) * 100\n",
    "        \n",
    "    pitch_mod_factor = \"+\" + str(pitch_mod_factor) if pitch_mod_factor >= 0 else str(pitch_mod_factor)\n",
    "    \n",
    "    ssml = \"\"\"<speak><prosody amazon:max-duration=\"{max_len}ms\"><prosody pitch=\"{pitch_mod_factor}%\">{word}</prosody></prosody></speak>\"\"\".format(max_len=str(length), word=word, pitch_mod_factor=pitch_mod_factor)          \n",
    "    response = polly_client.start_speech_synthesis_task(VoiceId=voice_id,\n",
    "                OutputS3BucketName=sagemaker_session.default_bucket(),\n",
    "                OutputS3KeyPrefix=output_folder + bucket_prefix,\n",
    "                OutputFormat='mp3', \n",
    "                TextType = 'ssml',\n",
    "                Text = ssml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are giving the initial transcriptions to Amazon Polly in order to find the pitch of each individual word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating audio file for each word...\")\n",
    "\n",
    "polly_client = boto3.client('polly')\n",
    "polly_output_folder = \"polly-output-1/\"\n",
    "processing_util.clear_s3_folder(my_bucket, bucket_client, polly_output_folder)\n",
    "\n",
    "for transcribe_object in tqdm(transcription_list):\n",
    "    response = query_polly(polly_client, transcribe_object.content, transcribe_object.duration(), transcribe_object.index, polly_output_folder, 0, voice_id)\n",
    "    \n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Output from Amazon Polly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"polly-output-1/\"\n",
    "processing_util.clear_folder(prefix)\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    my_bucket.download_file(prefix+ file_name, prefix + file_name)\n",
    "\n",
    "time.sleep(5)\n",
    "print(\"Files moved from s3 to repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitch Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "polly_output_folder = \"polly-output-1/\"\n",
    "SONG_TRANSCRIPTION_PATH = \"song-transcription/transcribed_song.json\"\n",
    "\n",
    "\n",
    "polly_client = boto3.client('polly')\n",
    "polly_output_corrected_folder = \"polly-output-corrected/\"\n",
    "processing_util.clear_s3_folder(my_bucket, bucket_client, polly_output_corrected_folder)\n",
    "\n",
    "polly_output = sorted(os.listdir(polly_output_folder))\n",
    "song_transcription = json.load(open(SONG_TRANSCRIPTION_PATH, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "for transcription_item, mp3_file in list(zip(song_transcription, polly_output)):\n",
    "    \n",
    "    assert(mp3_file.startswith(transcription_item[\"index\"]))\n",
    "    audio_clip = audio_util.interpret_polly_output_file(polly_output_folder + mp3_file)\n",
    "    \n",
    "    pitch_mod = 0\n",
    "    if transcription_item[\"end_time\"] - transcription_item[\"start_time\"] > 50:\n",
    "        with io.capture_output() as captured:\n",
    "            pitch_mod = audio_util.pitch_difference(audio_clip, transcription_item[\"start_time\"], transcription_item[\"end_time\"], \"temp/\")\n",
    "            pitch_mod = 0 if pitch_mod is None else pitch_mod\n",
    "       \n",
    "    print(\"Content: {content}, Pitch Correction: {pitch_mod}, Pitch Factor: {pitch_factor}\".format(content=transcription_item[\"content\"], pitch_mod=pitch_mod, pitch_factor=(2**(1.0 * pitch_mod / 12.0)) - 1))\n",
    "    \n",
    "    response = query_polly(polly_client, transcription_item[\"content\"], transcription_item[\"end_time\"] - transcription_item[\"start_time\"], transcription_item[\"index\"], polly_output_corrected_folder, pitch_mod, voice_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Corrected Output from Amazon Polly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "processing_util.clear_folder(polly_output_corrected_folder)\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=polly_output_corrected_folder):\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    my_bucket.download_file(polly_output_corrected_folder+ file_name, polly_output_corrected_folder + file_name)\n",
    "\n",
    "time.sleep(5)\n",
    "print(\"Files moved from s3 to repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1:\n",
    "# POLLY_OUTPUT_FOLDER = polly_output_folder\n",
    "# Version 2:\n",
    "POLLY_OUTPUT_FOLDER = polly_output_corrected_folder\n",
    "BACKGROUND_FOLDER = \"isolated-background/\"\n",
    "FINAL_OUTPUT_FOLDER = \"final-output/\"\n",
    "SONG_TRANSCRIPTION_PATH = \"song-transcription/transcribed_song.json\"\n",
    "BATCH_LENGTH = 30000 # m\n",
    "\n",
    "# Generate Background\n",
    "background_mp3_files = [BACKGROUND_FOLDER + s for s in sorted(os.listdir(BACKGROUND_FOLDER))]\n",
    "background_mp3 = audio_util.interpret_polly_output_file(background_mp3_files[0])\n",
    "background_mp3_files.pop(0)\n",
    "for fname in tqdm(background_mp3_files):\n",
    "    background_mp3 += audio_util.interpret_polly_output_file(fname)\n",
    "background_mp3.export(FINAL_OUTPUT_FOLDER + \"background.mp3\", format=\"mp3\")\n",
    "\n",
    "# Generate Vocals\n",
    "polly_output = sorted(os.listdir(POLLY_OUTPUT_FOLDER))\n",
    "song_transcription = json.load(open(SONG_TRANSCRIPTION_PATH, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "vocal_mp3 = audio_util.get_silence(1)\n",
    "expected_start_time = 0\n",
    "\n",
    "for transcription_item, mp3_file in tqdm(list(zip(song_transcription, polly_output))):\n",
    "    if expected_start_time < transcription_item[\"start_time\"]:\n",
    "        vocal_mp3 += audio_util.get_silence(transcription_item[\"start_time\"] - expected_start_time)\n",
    "        expected_start_time = transcription_item[\"start_time\"]\n",
    "\n",
    "    assert(mp3_file.startswith(transcription_item[\"index\"]))\n",
    "    audio_clip = audio_util.interpret_polly_output_file(POLLY_OUTPUT_FOLDER + mp3_file)\n",
    "\n",
    "# Version 1.1: No pitch modification, more stable\n",
    "    vocal_mp3 += audio_clip\n",
    "    expected_start_time += len(audio_clip)\n",
    "\n",
    "vocal_mp3.export(FINAL_OUTPUT_FOLDER + \"vocals.mp3\", format=\"mp3\")\n",
    "\n",
    "\n",
    "print(\"Overlaying the vocals with the accompaniment and generating the final audio file...\")\n",
    "final_audio = background_mp3.overlay(vocal_mp3)\n",
    "final_audio.export(FINAL_OUTPUT_FOLDER + \"final_audio.mp3\", format=\"mp3\")\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to the Song Cover :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(\"final-output/final_audio.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
