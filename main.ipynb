{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 14, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 8 (delta 2), reused 8 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (8/8), done.\n",
      "From https://github.com/basilwong/awstest1\n",
      "   9a15831..70308c6  master     -> origin/master\n",
      "Updating 9a15831..70308c6\n",
      "Fast-forward\n",
      " ...dio_file_1586688313.4434075.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " ...dio_file_1586688359.6707158.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " ...udio_file_1586688451.638458.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " ...dio_file_1586688129.2001228.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " ...udio_file_1586688267.341563.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " ...udio_file_1586688221.484059.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " ...dio_file_1586688175.3730624.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " ...dio_file_1586688497.7542431.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m2523634\u001b[m bytes\n",
      " ...udio_file_1586688405.760855.mp3_accompaniment.wav | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " .../0audio_file_1586688313.4434075.mp3_vocals.wav    | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " .../1audio_file_1586688359.6707158.mp3_vocals.wav    | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " .../2audio_file_1586688451.638458.mp3_vocals.wav     | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " .../3audio_file_1586688129.2001228.mp3_vocals.wav    | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " .../4audio_file_1586688267.341563.mp3_vocals.wav     | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " .../5audio_file_1586688221.484059.mp3_vocals.wav     | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " .../6audio_file_1586688175.3730624.mp3_vocals.wav    | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " .../7audio_file_1586688497.7542431.mp3_vocals.wav    | Bin \u001b[31m0\u001b[m -> \u001b[32m2523634\u001b[m bytes\n",
      " .../8audio_file_1586688405.760855.mp3_vocals.wav     | Bin \u001b[31m0\u001b[m -> \u001b[32m10584058\u001b[m bytes\n",
      " src/audio_util.py                                    |  13 \u001b[32m+++++++++++++\u001b[m\n",
      " src/silence.mp3                                      | Bin \u001b[31m0\u001b[m -> \u001b[32m186262\u001b[m bytes\n",
      " 20 files changed, 13 insertions(+)\n",
      " create mode 100644 source-separation-output/background/0audio_file_1586688313.4434075.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/background/1audio_file_1586688359.6707158.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/background/2audio_file_1586688451.638458.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/background/3audio_file_1586688129.2001228.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/background/4audio_file_1586688267.341563.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/background/5audio_file_1586688221.484059.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/background/6audio_file_1586688175.3730624.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/background/7audio_file_1586688497.7542431.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/background/8audio_file_1586688405.760855.mp3_accompaniment.wav\n",
      " create mode 100644 source-separation-output/vocals/0audio_file_1586688313.4434075.mp3_vocals.wav\n",
      " create mode 100644 source-separation-output/vocals/1audio_file_1586688359.6707158.mp3_vocals.wav\n",
      " create mode 100644 source-separation-output/vocals/2audio_file_1586688451.638458.mp3_vocals.wav\n",
      " create mode 100644 source-separation-output/vocals/3audio_file_1586688129.2001228.mp3_vocals.wav\n",
      " create mode 100644 source-separation-output/vocals/4audio_file_1586688267.341563.mp3_vocals.wav\n",
      " create mode 100644 source-separation-output/vocals/5audio_file_1586688221.484059.mp3_vocals.wav\n",
      " create mode 100644 source-separation-output/vocals/6audio_file_1586688175.3730624.mp3_vocals.wav\n",
      " create mode 100644 source-separation-output/vocals/7audio_file_1586688497.7542431.mp3_vocals.wav\n",
      " create mode 100644 source-separation-output/vocals/8audio_file_1586688405.760855.mp3_vocals.wav\n",
      " create mode 100644 src/silence.mp3\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.23.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from sagemaker import ModelPackage\n",
    "\n",
    "\n",
    "# some_file.py\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('src')\n",
    "\n",
    "!pip install pydub\n",
    "\n",
    "import audio_util\n",
    "import processing_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution role\n",
    "role = get_execution_role()\n",
    "# S3 prefixes\n",
    "common_prefix = \"source_separation\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "# Sagemaker Session\n",
    "sagemaker_session = sage.Session()\n",
    "# Arn for Source Separator Model Package\n",
    "modelpackage_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import ModelPackage\n",
    "\n",
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Batch Job\n",
    "\n",
    "Note that if the initial audio file is longer than around 30 seconds, it is too large for the model. The split_mp3() method in  src.audio_util works around this by splitting an mp3 file into 30 second segments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_util.split_mp3(\"../songs/drake-toosie_slide.mp3\", \"../source-separation-input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-075178354542/source_separation/batch-inference-input-data\n"
     ]
    }
   ],
   "source": [
    "batch_input_folder = \"source-separation-input\"\n",
    "\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(batch_input_folder, key_prefix=batch_inference_input_prefix)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2020-04-13 04:48:15 +0000] [10] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2020-04-13 04:48:15 +0000] [10] [INFO] Listening at: unix:/tmp/gunicorn.sock (10)\u001b[0m\n",
      "\u001b[34m[2020-04-13 04:48:15 +0000] [10] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-04-13 04:48:15 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2020-04-13 04:48:15 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-04-13 04:48:15 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2020-04-13 04:48:15 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-13 04:48:39.079016: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:48:39 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:48:39 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753319.4046214.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753319.4046214.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m2020-04-13 04:48:39.079016: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:48:39 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:48:39 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753319.4046214.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753319.4046214.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-13 04:48:40.715688: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m2020-04-13 04:48:40.715688: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[32m2020-04-13T04:48:39.376:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m['audio_file_1586753319.4046214.mp3_vocals.wav', 'audio_file_1586753319.4046214.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[35m['audio_file_1586753319.4046214.mp3_vocals.wav', 'audio_file_1586753319.4046214.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:49:25 +0000] \"POST /invocations HTTP/1.1\" 200 19391978 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753365.3933253.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753365.3933253.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:49:25 +0000] \"POST /invocations HTTP/1.1\" 200 19391978 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753365.3933253.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753365.3933253.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-13 04:49:26.852623: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35m2020-04-13 04:49:26.852623: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753411.4280498.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753411.4280498.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753411.4280498.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753411.4280498.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m['audio_file_1586753411.4280498.mp3_accompaniment.wav', 'audio_file_1586753411.4280498.mp3_vocals.wav']\u001b[0m\n",
      "\u001b[35m['audio_file_1586753411.4280498.mp3_accompaniment.wav', 'audio_file_1586753411.4280498.mp3_vocals.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:50:57 +0000] \"POST /invocations HTTP/1.1\" 200 19436044 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753457.4691133.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753457.4691133.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:50:57 +0000] \"POST /invocations HTTP/1.1\" 200 19436044 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753457.4691133.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753457.4691133.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:51:43 +0000] \"POST /invocations HTTP/1.1\" 200 19435235 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753503.4803622.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753503.4803622.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:51:43 +0000] \"POST /invocations HTTP/1.1\" 200 19435235 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753503.4803622.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753503.4803622.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-13 04:51:44.811950: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m2020-04-13 04:51:44.811950: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m['audio_file_1586753503.4803622.mp3_accompaniment.wav', 'audio_file_1586753503.4803622.mp3_vocals.wav']\u001b[0m\n",
      "\u001b[35m['audio_file_1586753503.4803622.mp3_accompaniment.wav', 'audio_file_1586753503.4803622.mp3_vocals.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:52:29 +0000] \"POST /invocations HTTP/1.1\" 200 19477349 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:52:29 +0000] \"POST /invocations HTTP/1.1\" 200 19477349 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753549.2771432.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753549.2771432.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753549.2771432.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753549.2771432.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m['audio_file_1586753549.2771432.mp3_vocals.wav', 'audio_file_1586753549.2771432.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[35m['audio_file_1586753549.2771432.mp3_vocals.wav', 'audio_file_1586753549.2771432.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:53:15 +0000] \"POST /invocations HTTP/1.1\" 200 19460915 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753595.1332912.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753595.1332912.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:53:15 +0000] \"POST /invocations HTTP/1.1\" 200 19460915 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753595.1332912.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753595.1332912.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m['audio_file_1586753595.1332912.mp3_vocals.wav', 'audio_file_1586753595.1332912.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[35m['audio_file_1586753595.1332912.mp3_vocals.wav', 'audio_file_1586753595.1332912.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:54:01 +0000] \"POST /invocations HTTP/1.1\" 200 19459102 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753641.1667993.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753641.1667993.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:54:01 +0000] \"POST /invocations HTTP/1.1\" 200 19459102 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753641.1667993.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753641.1667993.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:54:47 +0000] \"POST /invocations HTTP/1.1\" 200 19035684 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586753687.3142326.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586753687.3142326.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:54:47 +0000] \"POST /invocations HTTP/1.1\" 200 19035684 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586753687.3142326.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586753687.3142326.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m['audio_file_1586753687.3142326.mp3_accompaniment.wav', 'audio_file_1586753687.3142326.mp3_vocals.wav']\u001b[0m\n",
      "\u001b[35m['audio_file_1586753687.3142326.mp3_accompaniment.wav', 'audio_file_1586753687.3142326.mp3_vocals.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Apr/2020:04:55:00 +0000] \"POST /invocations HTTP/1.1\" 200 4379043 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Apr/2020:04:55:00 +0000] \"POST /invocations HTTP/1.1\" 200 4379043 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-075178354542/source_separation/batch-transform-output\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import uuid\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://'+bucket+'/'+common_prefix+'/batch-transform-output')\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Batch Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1.mp3.out\n",
      "input2.mp3.out\n",
      "input3.mp3.out\n",
      "input4.mp3.out\n",
      "input5.mp3.out\n",
      "input6.mp3.out\n",
      "input7.mp3.out\n",
      "input8.mp3.out\n",
      "input9.mp3.out\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "audio_util.clear_folder('source-separation-output/batch-transform-output')\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'source-separation-output/batch-transform-output/output-{}.zip'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-3.zip\n",
      "output-6.zip\n",
      "output-8.zip\n",
      "output-9.zip\n",
      "output-1.zip\n",
      "output-4.zip\n",
      "output-7.zip\n",
      "output-2.zip\n",
      "output-5.zip\n"
     ]
    }
   ],
   "source": [
    "# Extracting files from zip files. \n",
    "audio_util.clear_folder('source-separation-output/extracted')\n",
    "for file in os.listdir('source-separation-output/batch-transform-output'):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile('source-separation-output/batch-transform-output/'+file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('source-separation-output/extracted/'+file.split('.')[0]+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0audio_file_1586753319.4046214.mp3_accompaniment.wav\n",
      "0audio_file_1586753319.4046214.mp3_vocals.wav\n",
      "1audio_file_1586753365.3933253.mp3_accompaniment.wav\n",
      "1audio_file_1586753365.3933253.mp3_vocals.wav\n",
      "2audio_file_1586753411.4280498.mp3_vocals.wav\n",
      "2audio_file_1586753411.4280498.mp3_accompaniment.wav\n",
      "3audio_file_1586753457.4691133.mp3_vocals.wav\n",
      "3audio_file_1586753457.4691133.mp3_accompaniment.wav\n",
      "4audio_file_1586753503.4803622.mp3_vocals.wav\n",
      "4audio_file_1586753503.4803622.mp3_accompaniment.wav\n",
      "5audio_file_1586753549.2771432.mp3_vocals.wav\n",
      "5audio_file_1586753549.2771432.mp3_accompaniment.wav\n",
      "6audio_file_1586753595.1332912.mp3_vocals.wav\n",
      "6audio_file_1586753595.1332912.mp3_accompaniment.wav\n",
      "7audio_file_1586753641.1667993.mp3_accompaniment.wav\n",
      "7audio_file_1586753641.1667993.mp3_vocals.wav\n",
      "8audio_file_1586753687.3142326.mp3_accompaniment.wav\n",
      "8audio_file_1586753687.3142326.mp3_vocals.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Separating the vocal files and the background sound files.\n",
    "audio_util.clear_folder('source-separation-output/vocals')\n",
    "audio_util.clear_folder('source-separation-output/background')\n",
    "for i, folder in enumerate(sorted(os.listdir('source-separation-output/extracted/'))):\n",
    "    for file in os.listdir('source-separation-output/extracted/' + folder + '/output'):\n",
    "        new_file_name = str(i).zfill(5)\n",
    "        print(new_file_name)\n",
    "        if \"vocals\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/vocals/' + new_file_name)\n",
    "        elif \"accompaniment\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/background/' + new_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Vocal Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribe input uploaded to s3://sagemaker-us-east-2-075178354542/transcribe-input\n"
     ]
    }
   ],
   "source": [
    "# Upload the Vocal files onto s3\n",
    "local_vocals_folder = \"source-separation-output/vocals/\"\n",
    "transcribe_input_prefix = \"transcribe-input\"\n",
    "\n",
    "transcribe_input = sagemaker_session.upload_data(local_vocals_folder, key_prefix=transcribe_input_prefix)\n",
    "print(\"Transcribe input uploaded to \" + transcribe_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing: 0audio_file_1586753319.4046214.mp3_vocals.wav\n",
      "Transcribing: 1audio_file_1586753365.3933253.mp3_vocals.wav\n",
      "Transcribing: 2audio_file_1586753411.4280498.mp3_vocals.wav\n",
      "Transcribing: 3audio_file_1586753457.4691133.mp3_vocals.wav\n",
      "Transcribing: 4audio_file_1586753503.4803622.mp3_vocals.wav\n",
      "Transcribing: 5audio_file_1586753549.2771432.mp3_vocals.wav\n",
      "Transcribing: 6audio_file_1586753595.1332912.mp3_vocals.wav\n",
      "Transcribing: 7audio_file_1586753641.1667993.mp3_vocals.wav\n",
      "Transcribing: 8audio_file_1586753687.3142326.mp3_vocals.wav\n"
     ]
    }
   ],
   "source": [
    "# Start a transcription job for each file. Add the transcription to finsihed jobs once finished. \n",
    "\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "transcribe = boto3.client('transcribe')\n",
    "output_bucket_name = \"transcribe-output\"\n",
    "uri_prefix = \"https://sagemaker-us-east-2-075178354542.s3.us-east-2.amazonaws.com/transcribe-input/\"\n",
    "finished_jobs = list()\n",
    "\n",
    "for file in sorted(os.listdir(local_vocals_folder)):\n",
    "\n",
    "    print(\"Transcribing: \" + file)\n",
    "    job_uri = uri_prefix + file\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=file,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='wav',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=file)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "    \n",
    "    api_data = requests.get(url=status['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "    data = api_data.json()\n",
    "    finished_jobs.append(data)\n",
    "    dump_file_name = 'transcribe-output/transcription' + file.split(\"audio\")[0] + '.json'\n",
    "    # Writing to json files for analysis purposes.\n",
    "    with open(dump_file_name, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    transcribe.delete_transcription_job(TranscriptionJobName=file)\n",
    "    \n",
    "finished_jobs.sort(key=lambda x : x['jobName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0caac80b-36eb-4400-bb48-87638b55d504',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 13 Apr 2020 09:54:13 GMT',\n",
       "   'x-amzn-requestid': '0caac80b-36eb-4400-bb48-87638b55d504',\n",
       "   'content-length': '0',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe.delete_transcription_job(TranscriptionJobName=\"0audio_file_1586753319.4046214.mp3_vocals.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giving Transcriptions to Amazon Polly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transcribe_output_folder = \"transcribe_output/\"\n",
    "index = 0\n",
    "\n",
    "for file in sorted(os.listdir(transcribe_output_folder)):\n",
    "    \n",
    "    transcription_batch = processing_util.load_json(transcribe_output_folder + file)\n",
    "    expected_start_time = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixing Audio:\n",
    "\n",
    "https://stackoverflow.com/questions/7629873/how-do-i-mix-audio-files-using-python\n",
    "\n",
    "Pitch Modulation:\n",
    "\n",
    "https://stackoverflow.com/questions/38923438/does-pydub-support-pitch-modulation\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
