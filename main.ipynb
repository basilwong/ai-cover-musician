{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting objects: 58, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (57/57), done.\n",
      "Writing objects: 100% (58/58), 129.68 KiB | 10.81 MiB/s, done.\n",
      "Total 58 (delta 5), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (5/5), completed with 4 local objects.\u001b[K\n",
      "remote: This repository moved. Please use the new location:\u001b[K\n",
      "remote:   https://github.com/basilwong/sagemaker-repo.git\u001b[K\n",
      "To https://github.com/basilwong/awstest1.git\n",
      "   f6a41aa..5c02458  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.23.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os\n",
    "import json \n",
    "import uuid\n",
    "import requests\n",
    "\n",
    "# Installing src dependency.\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('src')\n",
    "\n",
    "!pip install pydub\n",
    "import audio_util\n",
    "import processing_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution role\n",
    "role = get_execution_role()\n",
    "# S3 prefixes\n",
    "common_prefix = \"source_separation\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "# Sagemaker Session\n",
    "sagemaker_session = sage.Session()\n",
    "# Arn for Source Separator Model Package\n",
    "modelpackage_arn = 'arn:aws:sagemaker:us-east-2:057799348421:model-package/source-separation-v11570291536-75ed8128ecee95e142ec4404d884ecad'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Corresponding IAM Role, add the following policies:\n",
    "\n",
    "* AmazonTranscribeFullAccess\n",
    "* AWSMarketplaceManageSubscriptions\n",
    "* AmazonPollyFullAccess\n",
    "* AmazonSageMakerFullAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/x-recordio-protobuf')\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                     model_package_arn=modelpackage_arn,\n",
    "                     sagemaker_session=sagemaker_session,\n",
    "                     predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Batch Job\n",
    "\n",
    "Note that if the initial audio file is longer than around 30 seconds, it is too large for the model. The split_mp3() method in  src.audio_util works around this by splitting an mp3 file into 30 second segments. \n",
    "\n",
    "This method requires ffmpeg as a dependency sice it uses pydub. Instead of installing it on the notebook, the code below was executed locally with ffmpeg installed. (```apt-get install ffmpeg``` for an Ubunutu machine, as I had trouble figuring out how to install it via yum).\n",
    "\n",
    "But no worries the output of the split_mp3() method has already been added to this repository so no need to go execute it for demo purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pydub/utils.py:193: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffprobe': 'ffprobe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-32bb9ebbbe05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The following lines of code require\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maudio_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"songs/drake-toosie_slide.mp3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../source-separation-input/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/awstest1/src/audio_util.py\u001b[0m in \u001b[0;36msplit_mp3\u001b[0;34m(fname, output_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[1;32m     28\u001b[0m     \u001b[0mTHIRTY_SEC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30000\u001b[0m \u001b[0;31m# in milliseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0msound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mtotal_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mnum_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_mp3\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mp3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mstdin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmediainfo_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             audio_streams = [x for x in info['streams']\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pydub/utils.py\u001b[0m in \u001b[0;36mmediainfo_json\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprober\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcommand_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdin_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    707\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffprobe': 'ffprobe'"
     ]
    }
   ],
   "source": [
    "# The following lines of code require \n",
    "audio_util.split_mp3(\"songs/drake-toosie_slide.mp3\", \"../source-separation-input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-075178354542/source_separation/batch-inference-input-data\n"
     ]
    }
   ],
   "source": [
    "batch_input_folder = \"source-separation-input\"\n",
    "\n",
    "transform_input = sagemaker_session.upload_data(batch_input_folder, key_prefix=batch_inference_input_prefix)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [11] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [11] [INFO] Listening at: unix:/tmp/gunicorn.sock (11)\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [11] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2020-04-15 00:39:31 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-15 00:40:07.431729: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:40:07 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:40:07 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911207.7691767.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911207.7691767.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[32m2020-04-15T00:40:07.738:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34mWARNING: Given output path /opt/ml/output/ does not exist. Trying to create it...\u001b[0m\n",
      "\u001b[34m['audio_file_1586911207.7691767.mp3_vocals.wav', 'audio_file_1586911207.7691767.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[35mWARNING: Given output path /opt/ml/output/ does not exist. Trying to create it...\u001b[0m\n",
      "\u001b[35m['audio_file_1586911207.7691767.mp3_vocals.wav', 'audio_file_1586911207.7691767.mp3_accompaniment.wav']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:40:54 +0000] \"POST /invocations HTTP/1.1\" 200 18898524 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911254.9186606.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911254.9186606.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:40:54 +0000] \"POST /invocations HTTP/1.1\" 200 18898524 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911254.9186606.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911254.9186606.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-15 00:40:56.383541: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35m2020-04-15 00:40:56.383541: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911301.739796.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911301.739796.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911301.739796.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911301.739796.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:42:28 +0000] \"POST /invocations HTTP/1.1\" 200 19154220 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911348.5407557.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911348.5407557.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:42:28 +0000] \"POST /invocations HTTP/1.1\" 200 19154220 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911348.5407557.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911348.5407557.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-15 00:42:29.921322: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m2020-04-15 00:42:29.921322: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:43:14 +0000] \"POST /invocations HTTP/1.1\" 200 19103055 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911394.9981234.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911394.9981234.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:43:14 +0000] \"POST /invocations HTTP/1.1\" 200 19103055 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911394.9981234.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911394.9981234.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34m2020-04-15 00:43:16.409269: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35m2020-04-15 00:43:16.409269: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911441.2943144.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911441.2943144.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911441.2943144.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911441.2943144.mp3\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:44:47 +0000] \"POST /invocations HTTP/1.1\" 200 19165147 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInput path : /tmp/audio_file_1586911487.6310062.mp3\u001b[0m\n",
      "\u001b[34mProducing source estimates for input mixture file /tmp/audio_file_1586911487.6310062.mp3\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:44:47 +0000] \"POST /invocations HTTP/1.1\" 200 19165147 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInput path : /tmp/audio_file_1586911487.6310062.mp3\u001b[0m\n",
      "\u001b[35mProducing source estimates for input mixture file /tmp/audio_file_1586911487.6310062.mp3\u001b[0m\n",
      "\u001b[34mTesting...\u001b[0m\n",
      "\u001b[35mTesting...\u001b[0m\n",
      "\u001b[34mNum of variables64\u001b[0m\n",
      "\u001b[34mPre-trained model restored for song prediction\u001b[0m\n",
      "\u001b[35mNum of variables64\u001b[0m\n",
      "\u001b[35mPre-trained model restored for song prediction\u001b[0m\n",
      "\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:45:11 +0000] \"POST /invocations HTTP/1.1\" 200 8532734 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:45:11 +0000] \"POST /invocations HTTP/1.1\" 200 8532734 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Apr/2020:00:45:11 +0000] \"POST /invocations HTTP/1.1\" 200 8532734 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Apr/2020:00:45:11 +0000] \"POST /invocations HTTP/1.1\" 200 8532734 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-075178354542/source_separation/batch-transform-output\n"
     ]
    }
   ],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge', strategy='SingleRecord', output_path='s3://'+bucket+'/'+common_prefix+'/batch-transform-output')\n",
    "transformer.transform(transform_input, content_type='application/x-recordio-protobuf')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Batch Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1.mp3.out\n",
      "input2.mp3.out\n",
      "input3.mp3.out\n",
      "input4.mp3.out\n",
      "input5.mp3.out\n",
      "input6.mp3.out\n",
      "input7.mp3.out\n"
     ]
    }
   ],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"source_separation/batch-transform-output/\"\n",
    "i = 0\n",
    "audio_util.clear_folder('source-separation-output/batch-transform-output')\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    i = i + 1\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    print(file_name)\n",
    "    my_bucket.download_file(prefix+ file_name, 'source-separation-output/batch-transform-output/output-{}.zip'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-3.zip\n",
      "output-6.zip\n",
      "output-1.zip\n",
      "output-4.zip\n",
      "output-7.zip\n",
      "output-2.zip\n",
      "output-5.zip\n"
     ]
    }
   ],
   "source": [
    "# Extracting files from zip files. \n",
    "audio_util.clear_folder('source-separation-output/extracted')\n",
    "for file in os.listdir('source-separation-output/batch-transform-output'):\n",
    "    print(file)\n",
    "    with zipfile.ZipFile('source-separation-output/batch-transform-output/'+file, 'r') as zip_ref:\n",
    "        zip_ref.extractall('source-separation-output/extracted/'+file.split('.')[0]+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the vocal files and the background sound files.\n",
    "audio_util.clear_folder('source-separation-output/vocals')\n",
    "audio_util.clear_folder('source-separation-output/background')\n",
    "for i, folder in enumerate(sorted(os.listdir('source-separation-output/extracted/'))):\n",
    "    for file in os.listdir('source-separation-output/extracted/' + folder + '/output'):\n",
    "        new_file_name = str(i).zfill(5) + \".wav\"\n",
    "        if \"vocals\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/vocals/vocals' + new_file_name)\n",
    "        elif \"accompaniment\" in file:\n",
    "            os.rename('source-separation-output/extracted/' + folder + '/output/' + file, 'source-separation-output/background/background' + new_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Vocal Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribe input uploaded to s3://sagemaker-us-east-2-075178354542/transcribe-input\n"
     ]
    }
   ],
   "source": [
    "# Upload the Vocal files onto s3\n",
    "local_vocals_folder = \"source-separation-output/vocals/\"\n",
    "transcribe_input_prefix = \"transcribe-input\"\n",
    "\n",
    "transcribe_input = sagemaker_session.upload_data(local_vocals_folder, key_prefix=transcribe_input_prefix)\n",
    "print(\"Transcribe input uploaded to \" + transcribe_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing: vocals00000.wav\n",
      "Transcribing: vocals00001.wav\n",
      "Transcribing: vocals00002.wav\n",
      "Transcribing: vocals00003.wav\n",
      "Transcribing: vocals00004.wav\n",
      "Transcribing: vocals00005.wav\n",
      "Transcribing: vocals00006.wav\n"
     ]
    }
   ],
   "source": [
    "# Start a transcription job for each file. Add the transcription to finsihed jobs once finished. \n",
    "transcribe = boto3.client('transcribe')\n",
    "output_bucket_name = \"transcribe-output\"\n",
    "audio_util.clear_folder('transcribe-output')\n",
    "uri_prefix = \"https://sagemaker-us-east-2-075178354542.s3.us-east-2.amazonaws.com/transcribe-input/\"\n",
    "finished_jobs = list()\n",
    "\n",
    "for file in sorted(os.listdir(local_vocals_folder)):\n",
    "\n",
    "    print(\"Transcribing: \" + file)\n",
    "    job_uri = uri_prefix + file\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=file,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='wav',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    while True:\n",
    "        status = transcribe.get_transcription_job(TranscriptionJobName=file)\n",
    "        if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "    \n",
    "    api_data = requests.get(url=status['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "    data = api_data.json()\n",
    "    finished_jobs.append(data)\n",
    "    dump_file_name = 'transcribe-output/transcription' + file.split(\".\")[0] + '.json'\n",
    "    # Writing to json files for analysis purposes.\n",
    "    with open(dump_file_name, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    transcribe.delete_transcription_job(TranscriptionJobName=file)\n",
    "    \n",
    "finished_jobs.sort(key=lambda x : x['jobName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'd9ebc7de-4303-47be-bd62-554da8e183b6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 15 Apr 2020 01:09:40 GMT',\n",
       "   'x-amzn-requestid': 'd9ebc7de-4303-47be-bd62-554da8e183b6',\n",
       "   'content-length': '0',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe.delete_transcription_job(TranscriptionJobName=\"vocals00000.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Transcribe Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustable Variable:\n",
    "\n",
    "# Short words tend to be transcribed too short. So this manually extends them. \n",
    "extend_word_length_factor = 200 # (percent of total word duration)\n",
    "word_under_x_ms_long = 500\n",
    "\n",
    "# add_pause_for_gaps_greater_than = 100 # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching the batches back together, generate transcription list from all the batches. \n",
    "transcribe_output_folder = \"transcribe-output/\"\n",
    "offset = 0 # Takes into account that batches are sequential.\n",
    "transcription_list = list()\n",
    "index = 0\n",
    "for file in sorted(os.listdir(transcribe_output_folder)):\n",
    "    transcription_batch = json.load(open(transcribe_output_folder + file, \"r\", encoding=\"utf-8\"))\n",
    "    for map_item in transcription_batch[\"results\"][\"items\"]:\n",
    "        transcribe_object = processing_util.TranscriptionItem(map_item, index, offset)\n",
    "        index += 1\n",
    "        # Skip punctuation\n",
    "        if transcribe_object.is_word():\n",
    "            if transcribe_object.duration() < word_under_x_ms_long:\n",
    "                transcribe_object.end_time += extend_word_length_factor\n",
    "            transcription_list.append(transcribe_object)\n",
    "        # Increase word duration if very short\n",
    "\n",
    "    offset += 30000\n",
    "    \n",
    "# Add the \n",
    "transcribed_song_folder = \"song-transcription/\"\n",
    "audio_util.clear_folder(transcribed_song_folder)\n",
    "with open(transcribed_song_folder + \"transcribed_song.json\", 'w') as outfile:\n",
    "    json.dump([item.to_dict() for item in transcription_list], outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giving Transcriptions to Amazon Polly\n",
    "\n",
    "Amazon Polly is queried for each individual word to allow for easier control of timing and pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_polly(polly_client, word, length, prefix, output_folder):\n",
    "    \n",
    "    ssml = \"\"\"<speak><prosody amazon:max-duration=\"{max_len}ms\">{word}</prosody></speak>\"\"\".format(max_len=str(length), word=word)          \n",
    "    response = polly_client.start_speech_synthesis_task(VoiceId='Joey',\n",
    "                OutputS3BucketName='sagemaker-us-east-2-075178354542',\n",
    "                OutputS3KeyPrefix='polly-output/' + prefix,\n",
    "                OutputFormat='mp3', \n",
    "                TextType = 'ssml',\n",
    "                Text = ssml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polly Queried for: imagine\n",
      "Polly Queried for: there's\n",
      "Polly Queried for: no\n",
      "Polly Queried for: heaven\n",
      "Polly Queried for: It's\n",
      "Polly Queried for: easy\n",
      "Polly Queried for: if\n",
      "Polly Queried for: you\n",
      "Polly Queried for: try\n",
      "Polly Queried for: No\n",
      "Polly Queried for: Hell\n",
      "Polly Queried for: no\n",
      "Polly Queried for: above\n",
      "Polly Queried for: us\n",
      "Polly Queried for: Only\n",
      "Polly Queried for: sky\n",
      "Polly Queried for: Imagine\n",
      "Polly Queried for: all\n",
      "Polly Queried for: the\n",
      "Polly Queried for: people\n",
      "Polly Queried for: with\n",
      "Polly Queried for: today\n",
      "Polly Queried for: it\n",
      "Polly Queried for: isn't\n",
      "Polly Queried for: todo\n",
      "Polly Queried for: nothing\n",
      "Polly Queried for: to\n",
      "Polly Queried for: kill\n",
      "Polly Queried for: No\n",
      "Polly Queried for: religion\n",
      "Polly Queried for: Thio\n",
      "Polly Queried for: Imagine\n",
      "Polly Queried for: all\n",
      "Polly Queried for: the\n",
      "Polly Queried for: bbo\n",
      "Polly Queried for: My\n",
      "Polly Queried for: me\n",
      "Polly Queried for: is\n",
      "Polly Queried for: you\n",
      "Polly Queried for: You\n",
      "Polly Queried for: may\n",
      "Polly Queried for: say\n",
      "Polly Queried for: I'm\n",
      "Polly Queried for: a\n",
      "Polly Queried for: dreamer\n",
      "Polly Queried for: but\n",
      "Polly Queried for: I'm\n",
      "Polly Queried for: not\n",
      "Polly Queried for: a\n",
      "Polly Queried for: real\n",
      "Polly Queried for: war\n",
      "Polly Queried for: I\n",
      "Polly Queried for: hope\n",
      "Polly Queried for: someday\n",
      "Polly Queried for: John\n",
      "Polly Queried for: and\n",
      "Polly Queried for: the\n",
      "Polly Queried for: way\n",
      "Polly Queried for: will\n",
      "Polly Queried for: be\n",
      "Polly Queried for: imagine\n",
      "Polly Queried for: no\n",
      "Polly Queried for: possessions\n",
      "Polly Queried for: I\n",
      "Polly Queried for: wonder\n",
      "Polly Queried for: if\n",
      "Polly Queried for: you\n",
      "Polly Queried for: can\n",
      "Polly Queried for: No\n",
      "Polly Queried for: need\n",
      "Polly Queried for: with\n",
      "Polly Queried for: green\n",
      "Polly Queried for: off\n",
      "Polly Queried for: Brother\n",
      "Polly Queried for: off\n",
      "Polly Queried for: man\n",
      "Polly Queried for: Imagine\n",
      "Polly Queried for: all\n",
      "Polly Queried for: the\n",
      "Polly Queried for: BDO\n",
      "Polly Queried for: Jerry\n",
      "Polly Queried for: No\n",
      "Polly Queried for: we're\n",
      "Polly Queried for: You\n",
      "Polly Queried for: may\n",
      "Polly Queried for: say\n",
      "Polly Queried for: I'm\n",
      "Polly Queried for: a\n",
      "Polly Queried for: dreamer\n",
      "Polly Queried for: but\n",
      "Polly Queried for: I'm\n",
      "Polly Queried for: not\n",
      "Polly Queried for: the\n",
      "Polly Queried for: only\n",
      "Polly Queried for: one\n",
      "Polly Queried for: I\n",
      "Polly Queried for: hope\n",
      "Polly Queried for: someday\n",
      "Polly Queried for: you\n",
      "Polly Queried for: John\n",
      "Polly Queried for: and\n",
      "Polly Queried for: the\n",
      "Polly Queried for: little\n",
      "Polly Queried for: one\n"
     ]
    }
   ],
   "source": [
    "polly_client = boto3.client('polly')\n",
    "polly_output_folder = \"polly-output/\"\n",
    "\n",
    "for transcribe_object in transcription_list:\n",
    "    \n",
    "    response = query_polly(polly_client, transcribe_object.content, transcribe_object.duration(), transcribe_object.index, polly_output_folder)\n",
    "\n",
    "    print(\"Polly Queried for: \" + transcribe_object.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Output from Amazon Polly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved from s3 to repo.\n"
     ]
    }
   ],
   "source": [
    "# Downloading files from s3.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sagemaker_session.default_bucket())\n",
    "prefix = \"polly-output/\"\n",
    "audio_util.clear_folder(prefix)\n",
    "\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix=prefix):\n",
    "    file_name = object_summary.key.split('/')[-1]\n",
    "    my_bucket.download_file(prefix+ file_name, prefix + file_name)\n",
    "    \n",
    "print(\"Files moved from s3 to repo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixing Audio:\n",
    "\n",
    "https://stackoverflow.com/questions/7629873/how-do-i-mix-audio-files-using-python\n",
    "\n",
    "Pitch Modulation:\n",
    "\n",
    "https://stackoverflow.com/questions/38923438/does-pydub-support-pitch-modulation\n",
    "\n",
    "Create Video:\n",
    "\n",
    "https://helpdeskgeek.com/windows-10/how-to-record-your-screen-on-windows-10/\n",
    "\n",
    "Music Video:\n",
    "\n",
    "https://www.oneimagevideo.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
